{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import gc\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "sns.set()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "building = pd.read_csv('../input/ashrae-energy-prediction/building_metadata.csv')\n",
    "weather_train = pd.read_csv('../input/ashrae-energy-prediction/weather_train.csv')\n",
    "weather_test = pd.read_csv('../input/ashrae-energy-prediction/weather_test.csv')\n",
    "train = pd.read_csv('../input/ashrae-energy-prediction/train.csv')\n",
    "test = pd.read_csv('../input/ashrae-energy-prediction/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge\n",
    "train = train.merge(building, on='building_id', how='left')\n",
    "test = test.merge(building, on='building_id', how='left')\n",
    "train = train.merge(weather_train, on=['site_id', 'timestamp'], how='left')\n",
    "test = test.merge(weather_test, on=['site_id', 'timestamp'], how='left')\n",
    "del weather_train, weather_test,building\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building_id           0\n",
      "meter                 0\n",
      "timestamp             0\n",
      "meter_reading         0\n",
      "site_id               0\n",
      "primary_use           0\n",
      "square_feet           0\n",
      "year_built            0\n",
      "floor_count           0\n",
      "air_temperature       0\n",
      "cloud_coverage        0\n",
      "dew_temperature       0\n",
      "precip_depth_1_hr     0\n",
      "sea_level_pressure    0\n",
      "wind_direction        0\n",
      "wind_speed            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Fill NaNs\n",
    "fill_w_neg_one = ['site_id']\n",
    "fill_w_zero = ['floor_count']\n",
    "fill_w_popular = ['primary_use']\n",
    "fill_w_mean = ['cloud_coverage','year_built','air_temperature','dew_temperature', \n",
    "              \"precip_depth_1_hr\", \"sea_level_pressure\", \"wind_direction\", \"wind_speed\"]\n",
    "\n",
    "for df in [train, test]:\n",
    "    for col in fill_w_neg_one:\n",
    "        df[col].fillna(-1, inplace=True)\n",
    "    for col in fill_w_popular:\n",
    "        df[col].fillna(df[col].value_counts()[0], inplace=True)\n",
    "    for col in fill_w_zero:\n",
    "        df[col].fillna(0, inplace=True)\n",
    "    for col in fill_w_mean:\n",
    "        df[col].fillna(df[col].mean(), inplace=True)\n",
    "print(train.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  4,  6,  1,  7, 11,  8,  9, 15,  2, 10,  3, 14, 13,  5, 12],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label encoding\n",
    "le = LabelEncoder()\n",
    "\n",
    "for df in [train, test]:\n",
    "    df[\"primary_use\"] = le.fit_transform(df[\"primary_use\"])\n",
    "    \n",
    "train[\"primary_use\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building_id           category\n",
      "meter                 category\n",
      "timestamp               object\n",
      "meter_reading          float64\n",
      "site_id               category\n",
      "primary_use           category\n",
      "square_feet              int32\n",
      "year_built             float16\n",
      "floor_count           category\n",
      "air_temperature        float32\n",
      "cloud_coverage         float16\n",
      "dew_temperature        float32\n",
      "precip_depth_1_hr      float16\n",
      "sea_level_pressure     float32\n",
      "wind_direction         float16\n",
      "wind_speed             float32\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Saving some memory setting types\n",
    "d_types = {'building_id': 'category', #np.int16,\n",
    "          'meter': 'category', # np.int8,\n",
    "          'site_id': 'category', #np.int8,\n",
    "          'primary_use': 'category',\n",
    "          'floor_count': 'category',\n",
    "          'square_feet': np.int32,\n",
    "          'year_built': np.float16,\n",
    "          'air_temperature': np.float32,\n",
    "          'cloud_coverage': np.float16,\n",
    "          'dew_temperature': np.float32,\n",
    "          'precip_depth_1_hr': np.float16,\n",
    "          'sea_level_pressure': np.float32,\n",
    "          'wind_direction': np.float16,\n",
    "          'wind_speed': np.float32}\n",
    "\n",
    "for df in [train, test]:\n",
    "    for feature in d_types: \n",
    "        df[feature] = df[feature].astype(d_types[feature])\n",
    "    \n",
    "print(train.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop cols\n",
    "drop_cols = ['wind_direction']\n",
    "for df in [train, test]: \n",
    "    df = df.drop(drop_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  building_id meter  timestamp  meter_reading site_id primary_use  \\\n",
      "0           0     0 2016-01-01            0.0       0           0   \n",
      "1           1     0 2016-01-01            0.0       0           0   \n",
      "2           2     0 2016-01-01            0.0       0           0   \n",
      "3           3     0 2016-01-01            0.0       0           0   \n",
      "4           4     0 2016-01-01            0.0       0           0   \n",
      "\n",
      "   log_square_feet  year_built floor_count  air_temperature  ...  \\\n",
      "0         8.914062         108         0.0             25.0  ...   \n",
      "1         7.910156         104         0.0             25.0  ...   \n",
      "2         8.585938          91         0.0             25.0  ...   \n",
      "3        10.070312         102         0.0             25.0  ...   \n",
      "4        11.664062          75         0.0             25.0  ...   \n",
      "\n",
      "   dew_temperature  precip_depth_1_hr  sea_level_pressure  wind_speed  \\\n",
      "0             20.0           0.796387         1019.700012         0.0   \n",
      "1             20.0           0.796387         1019.700012         0.0   \n",
      "2             20.0           0.796387         1019.700012         0.0   \n",
      "3             20.0           0.796387         1019.700012         0.0   \n",
      "4             20.0           0.796387         1019.700012         0.0   \n",
      "\n",
      "   dayofweek hour _meter_0 _meter_1 _meter_2 _meter_3  \n",
      "0          4    0     True    False    False    False  \n",
      "1          4    0     True    False    False    False  \n",
      "2          4    0     True    False    False    False  \n",
      "3          4    0     True    False    False    False  \n",
      "4          4    0     True    False    False    False  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# add non-imputed features \n",
    "def nonIFeatures(df):\n",
    "    #time_stamps\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n",
    "    df['dayofweek'] = df[\"timestamp\"].dt.dayofweek.astype('category') # vs weekend?\n",
    "    df[\"hour\"] = df[\"timestamp\"].dt.hour.astype('category')\n",
    "    #df[\"month\"] = df[\"timestamp\"].dt.month.astype('category')\n",
    "    \n",
    "    # each row should know about other meters \n",
    "    for i in range(4):\n",
    "        df[\"_meter_\"+str(i)] = df['building_id'].isin(\n",
    "            train.loc[train['meter'] == i].building_id.unique()).astype('category')\n",
    "    \n",
    "    df.rename(columns={\"square_feet\": \"log_square_feet\"}, inplace=True)\n",
    "    df['log_square_feet'] = np.float16(np.log(df['log_square_feet']))\n",
    "    df['year_built'] = np.uint8(df['year_built']-1900)    \n",
    "    \n",
    "for df in [train, test]:\n",
    "    df = nonIFeatures(df)\n",
    "    \n",
    "print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['building_id', 'meter', 'site_id', 'primary_use', 'log_square_feet',\n",
      "       'year_built', 'floor_count', 'air_temperature', 'cloud_coverage',\n",
      "       'dew_temperature', 'precip_depth_1_hr', 'sea_level_pressure',\n",
      "       'wind_speed', 'dayofweek', 'hour', '_meter_0', '_meter_1', '_meter_2',\n",
      "       '_meter_3'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>meter</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>meter_reading</th>\n",
       "      <th>site_id</th>\n",
       "      <th>primary_use</th>\n",
       "      <th>log_square_feet</th>\n",
       "      <th>year_built</th>\n",
       "      <th>floor_count</th>\n",
       "      <th>air_temperature</th>\n",
       "      <th>...</th>\n",
       "      <th>dew_temperature</th>\n",
       "      <th>precip_depth_1_hr</th>\n",
       "      <th>sea_level_pressure</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>hour</th>\n",
       "      <th>_meter_0</th>\n",
       "      <th>_meter_1</th>\n",
       "      <th>_meter_2</th>\n",
       "      <th>_meter_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [building_id, meter, timestamp, meter_reading, site_id, primary_use, log_square_feet, year_built, floor_count, air_temperature, cloud_coverage, dew_temperature, precip_depth_1_hr, sea_level_pressure, wind_speed, dayofweek, hour, _meter_0, _meter_1, _meter_2, _meter_3]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 21 columns]"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create test train\n",
    "train_y =  np.log1p(train[\"meter_reading\"]) # ask why\n",
    "train_X = train.drop([\"meter_reading\",\"timestamp\"], axis=1)\n",
    "test_X = test.drop([\"row_id\",\"timestamp\"], axis=1)\n",
    "\n",
    "gc.collect();\n",
    "\n",
    "print(train_X.columns)\n",
    "train.loc[train['meter_reading'] < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmsle scores:\n",
      " [-0.50787072 -0.46765246 -0.38312615 -0.40704553 -0.42841516]\n"
     ]
    }
   ],
   "source": [
    "# Rob hacking\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer, mean_squared_log_error\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "\n",
    "def rmsle(y, y_pred):\n",
    "    # hack to prevent negative numbers\n",
    "    return np.sqrt(mean_squared_log_error(y, y_pred.clip(0)))\n",
    "\n",
    "rmsle_scorer = make_scorer(\n",
    "    lambda y_true, y_pred : rmsle(y_true, y_pred), \n",
    "    greater_is_better=False)\n",
    "\n",
    "gbm=LGBMRegressor( task= 'train',\n",
    "                  boosting_type= 'gbdt',\n",
    "                  objective= 'regression',\n",
    "                  #n_estimators=6000,\n",
    "                  learning_rate= 0.09,\n",
    "                  feature_fraction= 0.9,\n",
    "                  bagging_fraction= 0.9,\n",
    "                  subsample=0.2,  # batches of 20% of the data\n",
    "                  subsample_freq=1,\n",
    "                  num_leaves=20,\n",
    "                  verbose= 100)\n",
    "\n",
    "scores = cross_val_score(gbm, train_X, train_y, cv=5, \n",
    "                         scoring=rmsle_scorer)\n",
    "print(\"rmsle scores:\\n\", scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(bagging_fraction=0.9, boosting_type='gbdt', class_weight=None,\n",
       "              colsample_bytree=1.0, feature_fraction=0.9,\n",
       "              importance_type='split', learning_rate=0.09, max_depth=-1,\n",
       "              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "              n_estimators=100, n_jobs=-1, num_leaves=20,\n",
       "              objective='regression', random_state=None, reg_alpha=0.0,\n",
       "              reg_lambda=0.0, silent=True, subsample=0.2,\n",
       "              subsample_for_bin=200000, subsample_freq=1, task='train',\n",
       "              verbose=100)"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm.fit(train_X, train_y, eval_metric=rmsle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1149  249  100   13   62    3   10  128    1   86    0   18    2   28\n",
      "   50    0    0    0    1]\n",
      "               feature  importance\n",
      "0          building_id        1149\n",
      "1                meter         249\n",
      "7      air_temperature         128\n",
      "2              site_id         100\n",
      "9      dew_temperature          86\n",
      "4      log_square_feet          62\n",
      "14                hour          50\n",
      "13           dayofweek          28\n",
      "11  sea_level_pressure          18\n",
      "3          primary_use          13\n",
      "6          floor_count          10\n",
      "5           year_built           3\n",
      "12          wind_speed           2\n",
      "8       cloud_coverage           1\n",
      "18            _meter_3           1\n",
      "10   precip_depth_1_hr           0\n",
      "15            _meter_0           0\n",
      "16            _meter_1           0\n",
      "17            _meter_2           0\n"
     ]
    }
   ],
   "source": [
    "print( gbm.feature_importances_)\n",
    "imprtc_df = pd.DataFrame()\n",
    "imprtc_df[\"feature\"] = train_X.columns   \n",
    "imprtc_df[\"importance\"] = gbm.feature_importances_\n",
    "print(imprtc_df.sort_values('importance', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 834/834 [01:51<00:00,  7.26it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "i=0\n",
    "res=[]\n",
    "step_size = 50000\n",
    "for j in tqdm(range(int(np.ceil(test_X.shape[0]/50000)))):\n",
    "    res.append(gbm.predict(test_X.iloc[i:i+step_size]))\n",
    "    i+=step_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv(\"../input/ashrae-energy-prediction/sample_submission.csv\")\n",
    "res = np.concatenate(res)\n",
    "# hack to prevent negative numbers\n",
    "sub[\"meter_reading\"] = np.expm1(res.clip(0))\n",
    "sub.to_csv(\"submission.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
