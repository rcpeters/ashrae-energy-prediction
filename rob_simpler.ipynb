{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 981,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "import pickle\n",
    "import gc\n",
    "from os import path\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from pandas.core.dtypes.dtypes import CategoricalDtype\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "sns.set()\n",
    "%matplotlib inline\n",
    "\n",
    "# label encoding\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1001,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dtype = {\n",
    "    'train': {'building_id': np.int16, 'meter': np.int8, 'meter_reading': np.float32},\n",
    "    'test': {'building_id': np.int16, 'meter': np.int8},\n",
    "    'building_metadata': {'site_id': np.int8, 'building_id': np.uint16, 'square_feet': np.int32, 'year_built': np.float32, 'floor_count': np.float32},\n",
    "    'weather' : {'site_id': np.int8, 'air_temperature': np.float32, 'cloud_coverage': np.float32, 'dew_temperature': np.float32,\n",
    "                     'precip_depth_1_hr': np.float32, 'sea_level_pressure': np.float32, 'wind_direction': np.float32, 'wind_speed': np.float32}\n",
    "}\n",
    "\n",
    "file_loc = {}    \n",
    "for dir_path in ['../input/ashrae-energy-prediction/','../input/_ashrae-energy-prediction/']:\n",
    "    for name in ['building_metadata','weather_train','weather_test','train','test']:\n",
    "        if path.exists(dir_path + name + '.csv'):\n",
    "            file_loc[name]= dir_path + name + '.csv'\n",
    "    \n",
    "    building = pd.read_csv(file_loc['building_metadata'], dtype=file_dtype['building_metadata'])\n",
    "    weather_train = pd.read_csv(file_loc['weather_train'], dtype=file_dtype['weather'])\n",
    "    weather_test = pd.read_csv(file_loc['weather_test'], dtype=file_dtype['weather'])\n",
    "    train = pd.read_csv(file_loc['train'], dtype=file_dtype['train'])\n",
    "    test = pd.read_csv(file_loc['test'], dtype=file_dtype['test'])\n",
    "\n",
    "train = train.merge(building, on='building_id', how='left')\n",
    "test = test.merge(building, on='building_id', how='left')\n",
    "train = train.merge(weather_train, on=['site_id', 'timestamp'], how='left')\n",
    "test = test.merge(weather_test, on=['site_id', 'timestamp'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1002,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note some building are built in the future!\n",
    "#train[ train['year_built'] > 2000]['year_built'].value_counts().sort_index().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1003,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToDatetime(df):\n",
    "    #time_stamps\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n",
    "    print('-- convertToDatetime done---------------------------')\n",
    "    print(df[[\"timestamp\"]].sample(n=20, random_state=42))\n",
    "    print('\\n\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1004,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add features we are 100% sure about\n",
    "def logSquareFeet(df):\n",
    "    #time_stamps\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])    \n",
    "    df.rename(columns={\"square_feet\": \"log_square_feet\"}, inplace=True)\n",
    "    df['log_square_feet'] = np.float16(np.log(df['log_square_feet']))\n",
    "    print('-- logSquareFeet done---------------------------')\n",
    "    print(df[[\"log_square_feet\"]].sample(n=20, random_state=42))\n",
    "    print('\\n\\n')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1005,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set types category types\n",
    "def setCatTypes(df):\n",
    "    df[\"primary_use\"]= df[\"primary_use\"].astype(\"category\")\n",
    "    df[\"meter\"] = df[\"meter\"].astype(\"category\")\n",
    "    df[\"site_id\"] = df[\"site_id\"].astype(\"category\")\n",
    "    df[\"building_id\"] = df[\"building_id\"].astype(\"category\")\n",
    "    print('-- setCatTypes done---------------------------')\n",
    "    print(df[[\"primary_use\",\"meter\",\"site_id\",\"building_id\"]].sample(n=20, random_state=42))\n",
    "    print('\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1006,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputing cloud coverage\n",
    "def imputeCloudCoverage(df):\n",
    "    # set age of building to mediam of site_id\n",
    "    # else if set ot overall median\n",
    "    median = df['cloud_coverage'].median()\n",
    "    # Set all year_built NaNs to site mean for year_built\n",
    "    for i, i_median in df.groupby(['site_id'])['cloud_coverage'].median().items():\n",
    "        print(str(i) + \" \" +str(i_median))\n",
    "        #print(i_median)\n",
    "        if not np.isnan(i_median):\n",
    "            df.loc[(df['cloud_coverage'].isnull()) & (df['site_id'] == i), 'cloud_coverage'] = i_median\n",
    "        else:\n",
    "            df.loc[(df['cloud_coverage'].isnull()) & (df['site_id'] == i), 'cloud_coverage'] = median\n",
    "    df['cloud_coverage'] = np.uint8(df['cloud_coverage'])\n",
    "    print('-- impute year built done---------------------------')\n",
    "    print(df.groupby(['site_id'])['cloud_coverage'].describe())\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1007,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates bucked categories for cloud coverage by time day\n",
    "# t[clound converage /2]c[hour divied /4]\n",
    "def cloudTimeCat(df):\n",
    "    tempDf = df[['cloud_coverage', 'hour']].astype('int')\n",
    "    tempDf['cloud_coverage'] = (tempDf['cloud_coverage']).astype('int')\n",
    "    tempDf['hour'] = (tempDf['hour']).astype('int')\n",
    "    tempDf = tempDf.astype('str')\n",
    "    df['cloud_time_cat'] = 'c' + tempDf['cloud_coverage'] + 't' + tempDf['hour']\n",
    "    df['cloud_time_cat'] = df['cloud_time_cat'].astype('category')\n",
    "    print('-- cloudHourCat done---------------------------')\n",
    "    print(df[['cloud_time_cat']].sample(n=20, random_state=42))\n",
    "    print('\\n\\n')                                                                      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1008,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating building_age\n",
    "def imputeYearBuilt(df):\n",
    "    # set age of building to mediam of site_id\n",
    "    # else if set ot overall median\n",
    "    year_built_median = df['year_built'].median()\n",
    "    # Set all year_built NaNs to site mean for year_built\n",
    "    for i, i_median in df.groupby(['site_id'])['year_built'].median().items():\n",
    "        if not np.isnan(i_median):\n",
    "            df.loc[(df['year_built'].isnull()) & (df['site_id'] == i), 'year_built'] = i_median\n",
    "        else:\n",
    "            df.loc[(df['year_built'].isnull()) & (df['site_id'] == i), 'year_built'] = year_built_median\n",
    "    df['building_age'] = np.uint8(df['year_built']-1900)\n",
    "    df['building_age'] = df['building_age']\n",
    "    print('-- impute year built done---------------------------')\n",
    "    print(df.groupby(['site_id'])['building_age'].describe())\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1009,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addMeterDummies(df):\n",
    "    for i in range(4):\n",
    "        df[\"_meter_\"+str(i)] = (df['building_id'].isin(\n",
    "            train.loc[train['meter'] == i].building_id.unique()))\n",
    "    print('-- addMeterDummies done---------------------------')\n",
    "    print(df[['_meter_0','_meter_1','_meter_2','_meter_3']].sample(n=20, random_state=42))\n",
    "    print('\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1010,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addTimeFeatures(df):\n",
    "    df['dayofweek'] = df[\"timestamp\"].dt.dayofweek.astype('category') # vs weekend?\n",
    "    df['weekday'] = df[\"timestamp\"].dt.weekday.astype('category')\n",
    "    df[\"hour\"] = df[\"timestamp\"].dt.hour.astype('category')\n",
    "    print('-- addTimeFeatures done---------------------------')\n",
    "    print(df['timestamp'].sample(n=20, random_state=42))\n",
    "    print('\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1011,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addRelativeHumidity(df):\n",
    "    # placeholder http://bmcnoldy.rsmas.miami.edu/Humidity.html\n",
    "    print('-- addRelativeHumidity done---------------------------')\n",
    "    #print(df['relative_humidity'].sample(n=20, random_state=42))\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- convertToDatetime done---------------------------\n",
      "                   timestamp\n",
      "14245562 2016-09-16 16:00:00\n",
      "1282718  2016-01-24 06:00:00\n",
      "13883790 2016-09-10 07:00:00\n",
      "4781820  2016-04-01 01:00:00\n",
      "10415393 2016-07-10 04:00:00\n",
      "1057008  2016-01-20 04:00:00\n",
      "4507399  2016-03-26 20:00:00\n",
      "19478829 2016-12-18 23:00:00\n",
      "8955615  2016-06-14 06:00:00\n",
      "13799839 2016-09-08 19:00:00\n",
      "15647011 2016-10-11 11:00:00\n",
      "2524294  2016-02-16 08:00:00\n",
      "10016102 2016-07-03 02:00:00\n",
      "3915750  2016-03-15 03:00:00\n",
      "17217526 2016-11-08 09:00:00\n",
      "11478    2016-01-01 04:00:00\n",
      "18919011 2016-12-09 02:00:00\n",
      "8709341  2016-06-09 21:00:00\n",
      "16313567 2016-10-23 07:00:00\n",
      "6289526  2016-04-27 20:00:00\n",
      "\n",
      "\n",
      "\n",
      "-- addRelativeHumidity done---------------------------\n",
      "\n",
      "\n",
      "\n",
      "-- addTimeFeatures done---------------------------\n",
      "14245562   2016-09-16 16:00:00\n",
      "1282718    2016-01-24 06:00:00\n",
      "13883790   2016-09-10 07:00:00\n",
      "4781820    2016-04-01 01:00:00\n",
      "10415393   2016-07-10 04:00:00\n",
      "1057008    2016-01-20 04:00:00\n",
      "4507399    2016-03-26 20:00:00\n",
      "19478829   2016-12-18 23:00:00\n",
      "8955615    2016-06-14 06:00:00\n",
      "13799839   2016-09-08 19:00:00\n",
      "15647011   2016-10-11 11:00:00\n",
      "2524294    2016-02-16 08:00:00\n",
      "10016102   2016-07-03 02:00:00\n",
      "3915750    2016-03-15 03:00:00\n",
      "17217526   2016-11-08 09:00:00\n",
      "11478      2016-01-01 04:00:00\n",
      "18919011   2016-12-09 02:00:00\n",
      "8709341    2016-06-09 21:00:00\n",
      "16313567   2016-10-23 07:00:00\n",
      "6289526    2016-04-27 20:00:00\n",
      "Name: timestamp, dtype: datetime64[ns]\n",
      "\n",
      "\n",
      "\n",
      "-- logSquareFeet done---------------------------\n",
      "          log_square_feet\n",
      "14245562        11.343750\n",
      "1282718         11.117188\n",
      "13883790        11.851562\n",
      "4781820         12.554688\n",
      "10415393        10.406250\n",
      "1057008         12.437500\n",
      "4507399         12.390625\n",
      "19478829        10.312500\n",
      "8955615         11.687500\n",
      "13799839        12.414062\n",
      "15647011        12.171875\n",
      "2524294          8.632812\n",
      "10016102         6.625000\n",
      "3915750         11.078125\n",
      "17217526        12.531250\n",
      "11478           11.507812\n",
      "18919011        11.335938\n",
      "8709341          8.625000\n",
      "16313567        11.015625\n",
      "6289526         10.828125\n",
      "\n",
      "\n",
      "\n",
      "-- impute year built done---------------------------\n",
      "             count       mean        std   min   25%    50%    75%    max\n",
      "site_id                                                                  \n",
      "0        1076662.0  96.309126  14.322800  68.0  85.0  101.0  107.0  116.0\n",
      "1         553357.0  60.398303  28.233491   0.0  56.0   60.0   70.0  107.0\n",
      "2        2530312.0  72.958444  21.578982   7.0  64.0   70.0   88.0  114.0\n",
      "3        2370097.0  61.244291  24.810568   0.0  61.0   61.0   61.0  117.0\n",
      "4         746746.0  53.378046  31.688006   3.0  24.0   54.0   70.0  116.0\n",
      "5         781776.0  62.752809  22.077142  19.0  66.0   76.0   76.0  113.0\n",
      "6         668133.0  69.000000   0.000000  69.0  69.0   69.0   69.0   69.0\n",
      "7         366681.0  61.468571  18.794832  11.0  55.0   64.0   70.0   95.0\n",
      "8         567915.0  69.000000   0.000000  69.0  69.0   69.0   69.0   69.0\n",
      "9        2679323.0  69.000000   0.000000  69.0  69.0   69.0   69.0   69.0\n",
      "10        411407.0  69.000000   0.000000  69.0  69.0   69.0   69.0   69.0\n",
      "11        119459.0  69.000000   0.000000  69.0  69.0   69.0   69.0   69.0\n",
      "12        315909.0  69.000000   0.000000  69.0  69.0   69.0   69.0   69.0\n",
      "13       2711763.0  69.000000   0.000000  69.0  69.0   69.0   69.0   69.0\n",
      "14       2501506.0  69.000000   0.000000  69.0  69.0   69.0   69.0   69.0\n",
      "15       1815054.0  61.011679  29.221940   2.0  46.0   63.0   81.0  114.0\n",
      "\n",
      "\n",
      "\n",
      "0 2.0\n",
      "1 0.0\n",
      "2 2.0\n",
      "3 4.0\n",
      "4 2.0\n",
      "5 0.0\n",
      "6 0.0\n",
      "7 nan\n",
      "8 2.0\n",
      "9 0.0\n",
      "10 0.0\n",
      "11 nan\n",
      "12 7.0\n",
      "13 2.0\n",
      "14 0.0\n",
      "15 0.0\n",
      "-- impute year built done---------------------------\n",
      "             count      mean       std  min  25%  50%  75%  max\n",
      "site_id                                                        \n",
      "0        1076662.0  2.593296  1.665471  0.0  2.0  2.0  4.0  9.0\n",
      "1         553357.0  0.016394  0.383773  0.0  0.0  0.0  0.0  9.0\n",
      "2        2530312.0  1.969933  1.637573  0.0  0.0  2.0  2.0  9.0\n",
      "3        2370097.0  3.929091  2.090933  0.0  4.0  4.0  4.0  9.0\n",
      "4         746746.0  1.928517  0.981933  0.0  2.0  2.0  2.0  9.0\n",
      "5         781776.0  0.090164  0.896296  0.0  0.0  0.0  0.0  9.0\n",
      "6         668133.0  0.424836  1.346262  0.0  0.0  0.0  0.0  9.0\n",
      "7         366681.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0\n",
      "8         567915.0  2.597922  1.676015  0.0  2.0  2.0  4.0  9.0\n",
      "9        2679323.0  0.370624  1.083932  0.0  0.0  0.0  0.0  9.0\n",
      "10        411407.0  0.272543  1.145751  0.0  0.0  0.0  0.0  9.0\n",
      "11        119459.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0\n",
      "12        315909.0  5.735772  2.234671  0.0  4.0  7.0  7.0  8.0\n",
      "13       2711763.0  2.445887  1.987124  0.0  2.0  2.0  2.0  9.0\n",
      "14       2501506.0  0.349933  1.199240  0.0  0.0  0.0  0.0  9.0\n",
      "15       1815054.0  0.538218  1.277137  0.0  0.0  0.0  0.0  9.0\n",
      "\n",
      "\n",
      "\n",
      "-- addMeterDummies done---------------------------\n",
      "          _meter_0  _meter_1  _meter_2  _meter_3\n",
      "14245562      True      True     False      True\n",
      "1282718       True      True     False     False\n",
      "13883790      True      True     False     False\n",
      "4781820       True      True     False      True\n",
      "10415393      True     False      True     False\n",
      "1057008       True     False     False     False\n",
      "4507399       True      True      True     False\n",
      "19478829      True     False     False     False\n",
      "8955615       True      True     False     False\n",
      "13799839      True      True      True     False\n",
      "15647011      True      True      True     False\n",
      "2524294       True     False     False     False\n",
      "10016102      True     False     False     False\n",
      "3915750       True      True      True     False\n",
      "17217526      True      True      True     False\n",
      "11478         True     False      True     False\n",
      "18919011      True      True      True     False\n",
      "8709341       True     False     False     False\n",
      "16313567      True     False     False     False\n",
      "6289526       True      True     False      True\n",
      "\n",
      "\n",
      "\n",
      "          floor_count  air_temperature  dew_temperature  precip_depth_1_hr  \\\n",
      "14245562          0.0        21.100000        10.000000           0.000000   \n",
      "1282718           3.0         0.600000         0.000000           3.000000   \n",
      "13883790          0.0        33.299999        13.300000           0.000000   \n",
      "4781820           0.0        21.700001        -5.600000           0.000000   \n",
      "10415393          0.0        19.400000        14.400000           0.796416   \n",
      "1057008           0.0         1.700000         0.300000           0.796416   \n",
      "4507399           0.0        22.799999        13.900000           0.000000   \n",
      "19478829          3.0         6.300000         4.100000           0.796416   \n",
      "8955615           0.0        30.600000         1.700000           0.000000   \n",
      "13799839          0.0        33.900002        22.200001           0.000000   \n",
      "15647011          0.0        13.300000         8.900000           0.000000   \n",
      "2524294           1.0        19.400000        17.799999          10.000000   \n",
      "10016102          1.0        24.400000        22.799999          -1.000000   \n",
      "3915750           0.0        24.400000        15.000000           0.000000   \n",
      "17217526          0.0        17.799999        17.200001          25.000000   \n",
      "11478             0.0        15.750197         7.722728           0.796416   \n",
      "18919011          0.0        -6.100000       -11.700000          -1.000000   \n",
      "8709341           0.0        27.799999         7.200000           0.000000   \n",
      "16313567          6.0         7.000000         7.000000           0.796416   \n",
      "6289526           0.0        12.200000         5.600000           0.000000   \n",
      "\n",
      "          sea_level_pressure  wind_speed  \n",
      "14245562         1026.099976     1.50000  \n",
      "1282718          1012.400024     4.10000  \n",
      "13883790         1009.599976     2.60000  \n",
      "4781820          1009.299988     5.70000  \n",
      "10415393         1010.099976     2.10000  \n",
      "1057008          1017.200012     3.00000  \n",
      "4507399          1012.000000     3.60000  \n",
      "19478829         1030.800049     5.00000  \n",
      "8955615          1008.299988     0.00000  \n",
      "13799839         1014.700012     3.50867  \n",
      "15647011         1019.500000     0.00000  \n",
      "2524294          1010.599976     5.10000  \n",
      "10016102         1019.099976     2.10000  \n",
      "3915750          1007.299988     1.50000  \n",
      "17217526         1019.400024     1.50000  \n",
      "11478             963.797485     3.50867  \n",
      "18919011         1033.699951     3.60000  \n",
      "8709341          1012.200012     4.60000  \n",
      "16313567          963.797485     7.20000  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6289526          1011.799988     2.10000  \n",
      "-- setCatTypes done---------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fill_w_neg_one = []\n",
    "fill_w_zero = ['floor_count']\n",
    "fill_w_popular = []\n",
    "fill_w_mean = ['air_temperature','dew_temperature', \n",
    "              \"precip_depth_1_hr\", \"sea_level_pressure\", \"wind_speed\"]\n",
    "\n",
    "def generalImputes(df):\n",
    "    for col in fill_w_neg_one:\n",
    "        df[col].fillna(-1, inplace=True)\n",
    "    for col in fill_w_popular:\n",
    "        df[col].fillna(df[col].value_counts()[0], inplace=True)\n",
    "    for col in fill_w_zero:\n",
    "        df[col].fillna(0, inplace=True)\n",
    "    for col in fill_w_mean:\n",
    "        df[col].fillna(df[col].mean(), inplace=True)\n",
    "    print(df[fill_w_neg_one + fill_w_zero + fill_w_popular + fill_w_mean].sample(n=20, random_state=42))\n",
    "    \n",
    "            \n",
    "for df in [train, test]:\n",
    "    convertToDatetime(df)\n",
    "    addRelativeHumidity(df)\n",
    "    addTimeFeatures(df)\n",
    "    logSquareFeet(df)\n",
    "    imputeYearBuilt(df)\n",
    "    imputeCloudCoverage(df)\n",
    "    #cloudTimeCat(df) this feature ranks high but doesn't change the score \n",
    "    addMeterDummies(df)\n",
    "    generalImputes(df)\n",
    "    setCatTypes(df)\n",
    "    gc.collect()\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('--NaN Checks')\n",
    "print(train.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['row_id','wind_direction','year_built','meter_reading','timestamp','precip_depth_1_hr'] # \n",
    "# create test train\n",
    "train_y =  np.log1p(train[\"meter_reading\"]) # ask why\n",
    "train_X = train.drop(filter(lambda i: i!='row_id', drop_cols), axis=1)\n",
    "test_X = test.drop(filter(lambda i: i!='meter_reading', drop_cols), axis=1)\n",
    "\n",
    "gc.collect();\n",
    "\n",
    "print(train_X.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer, mean_squared_log_error, mean_squared_error\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "\n",
    "def rmsle(y, y_pred):\n",
    "    # hack to prevent negative numbers\n",
    "    return np.sqrt(mean_squared_log_error(y, y_pred.clip(0)))\n",
    "\n",
    "def rmse(y, y_pred):\n",
    "    # hack to prevent negative numbers\n",
    "    return mean_squared_error(y, y_pred.clip(0))\n",
    "\n",
    "def rmsee(y, y_pred):\n",
    "    # hack to prevent negative numbers\n",
    "    return np.sqrt(mean_squared_log_error(np.expm1(y.clip(0)), np.expm1(y_pred.clip(0))))\n",
    "    \n",
    "rmsle_scorer = make_scorer(\n",
    "    lambda y_true, y_pred : rmsle(y_true, y_pred), \n",
    "    greater_is_better=False)\n",
    "\n",
    "rmse_scorer = make_scorer(\n",
    "    lambda y_true, y_pred : rmsle(y_true, y_pred), \n",
    "    greater_is_better=False)\n",
    "\n",
    "rmsee_scorer = make_scorer(\n",
    "    lambda y_true, y_pred : rmsee(y_true, y_pred), \n",
    "    greater_is_better=False)\n",
    "\n",
    "\n",
    "gbm=LGBMRegressor(n_estimators=100, # for accuracy use large numbers like 6000 \n",
    "                  learning_rate=0.23,\n",
    "                  feature_fraction=0.9,\n",
    "                  subsample=0.2,  # batches of 20% of the data\n",
    "                  subsample_freq=1,\n",
    "                  num_leaves=20,\n",
    "                  metric='rmse',\n",
    "                  verbose= 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Cross val testing - can be skipped\n",
    "\n",
    "scores = cross_val_score(gbm, train_X, train_y, cv=5, \n",
    "                         scoring=rmsee_scorer)\n",
    "print(\"rmsee scores:\\n\", scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit on all the data\n",
    "gbm.fit(train_X, train_y, eval_metric=rmsee, verbose=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( gbm.feature_importances_)\n",
    "imprtc_df = pd.DataFrame()\n",
    "imprtc_df[\"feature\"] = train_X.columns   \n",
    "imprtc_df[\"importance\"] = gbm.feature_importances_\n",
    "print(imprtc_df.sort_values('importance', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect();\n",
    "\n",
    "from tqdm import tqdm\n",
    "i=0\n",
    "res=[]\n",
    "step_size = 50000\n",
    "for j in tqdm(range(int(np.ceil(test_X.shape[0]/50000)))):\n",
    "    res.append(gbm.predict(test_X.iloc[i:i+step_size]))\n",
    "    i+=step_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 942,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-942-d7e0a2071a51>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# hack to prevent negative numbers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msub\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"meter_reading\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpm1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0msub\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"submission.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[0;32m   3018\u001b[0m                                  \u001b[0mdoublequote\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3019\u001b[0m                                  escapechar=escapechar, decimal=decimal)\n\u001b[1;32m-> 3020\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3021\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3022\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    170\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mUnicodeWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mwriter_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 172\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36m_save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    286\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 288\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save_chunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_save_chunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36m_save_chunk\u001b[1;34m(self, start_i, end_i)\u001b[0m\n\u001b[0;32m    300\u001b[0m                                   \u001b[0mdecimal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m                                   \u001b[0mdate_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m                                   quoting=self.quoting)\n\u001b[0m\u001b[0;32m    303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mcol_loc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36mto_native_types\u001b[1;34m(self, slicer, na_rep, float_format, decimal, quoting, **kwargs)\u001b[0m\n\u001b[0;32m   1992\u001b[0m         \u001b[1;31m# so do not pass it through the FloatArrayFormatter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1993\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfloat_format\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mdecimal\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'.'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1994\u001b[1;33m             \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1995\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1996\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mquoting\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\missing.py\u001b[0m in \u001b[0;36misna\u001b[1;34m(obj)\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[0mName\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m     \"\"\"\n\u001b[1;32m---> 99\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_isna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\missing.py\u001b[0m in \u001b[0;36m_isna_new\u001b[1;34m(obj)\u001b[0m\n\u001b[0;32m    112\u001b[0m                           \u001b[0mABCExtensionArray\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m                           ABCDatetimeArray, ABCTimedeltaArray)):\n\u001b[1;32m--> 114\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_isna_ndarraylike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCGeneric\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0misna\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\missing.py\u001b[0m in \u001b[0;36m_isna_ndarraylike\u001b[1;34m(obj)\u001b[0m\n\u001b[0;32m    218\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'i8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0miNaT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;31m# box\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sub = pd.read_csv(\"../input/ashrae-energy-prediction/sample_submission.csv\")\n",
    "res = np.concatenate(res)\n",
    "# hack to prevent negative numbers\n",
    "sub[\"meter_reading\"] = np.expm1(res.clip(0))\n",
    "sub.to_csv(\"submission.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
