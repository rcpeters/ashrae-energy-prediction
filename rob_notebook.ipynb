{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "import pickle\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion, TransformerMixin\n",
    "import gc\n",
    "from os import path\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from pandas.core.dtypes.dtypes import CategoricalDtype\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "sns.set()\n",
    "%matplotlib inline\n",
    "\n",
    "# label encoding\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputeWeather(weather_df, method:str='linear', gap_limit:int=None, limit_direction:str='forward'):\n",
    "    grouped_weather_df = weather_df.groupby('site_id').apply(lambda group: group.interpolate(method=method, limit=gap_limit, limit_direction=limit_direction))\n",
    "    \n",
    "    if 'cloud_coverage' in grouped_weather_df.columns:\n",
    "        grouped_weather_df['cloud_coverage'] = grouped_weather_df['cloud_coverage'].round(decimals=0).clip(0,8)\n",
    "    grouped_weather_df.reset_index(inplace=True)\n",
    "    return grouped_weather_df.drop('index', axis=1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "site_id                   0\n",
      "timestamp                 0\n",
      "air_temperature          55\n",
      "cloud_coverage        69173\n",
      "dew_temperature         113\n",
      "precip_depth_1_hr     50289\n",
      "sea_level_pressure    10618\n",
      "wind_direction         6268\n",
      "wind_speed              304\n",
      "dtype: int64\n",
      "site_id                   0\n",
      "timestamp                 0\n",
      "air_temperature           0\n",
      "cloud_coverage        17257\n",
      "dew_temperature           0\n",
      "precip_depth_1_hr     26423\n",
      "sea_level_pressure     8875\n",
      "wind_direction            0\n",
      "wind_speed                0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "181"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_dtype = {\n",
    "    'train': {'building_id': np.int16, 'meter': np.int8, 'meter_reading': np.float32},\n",
    "    'test': {'building_id': np.int16, 'meter': np.int8},\n",
    "    'building_metadata': {'site_id': np.int8, 'building_id': np.uint16, 'square_feet': np.int32, 'year_built': np.float32, 'floor_count': np.float32},\n",
    "    'weather' : {'site_id': np.int8, 'air_temperature': np.float32, 'cloud_coverage': np.float32, 'dew_temperature': np.float32,\n",
    "                     'precip_depth_1_hr': np.float32, 'sea_level_pressure': np.float32, 'wind_direction': np.float32, 'wind_speed': np.float32}\n",
    "}\n",
    "\n",
    "file_loc = {}    \n",
    "for dir_path in ['../input/ashrae-energy-prediction/','../input/_ashrae-energy-prediction/']:\n",
    "    for name in ['building_metadata','weather_train','weather_test','train','test']:\n",
    "        if path.exists(dir_path + name + '.csv'):\n",
    "            file_loc[name]= dir_path + name + '.csv'\n",
    "    \n",
    "    building = pd.read_csv(file_loc['building_metadata'], dtype=file_dtype['building_metadata'])\n",
    "    weather_train = pd.read_csv(file_loc['weather_train'], dtype=file_dtype['weather'])\n",
    "    weather_test = pd.read_csv(file_loc['weather_test'], dtype=file_dtype['weather'])\n",
    "    train = pd.read_csv(file_loc['train'], dtype=file_dtype['train'])\n",
    "    test = pd.read_csv(file_loc['test'], dtype=file_dtype['test'])\n",
    "\n",
    "print(weather_train.isna().sum())    \n",
    "weather_train = imputeWeather(weather_train)\n",
    "print(weather_train.isna().sum())\n",
    "weather_test = imputeWeather(weather_test)\n",
    "    \n",
    "train = train.merge(building, on='building_id', how='left')\n",
    "test = test.merge(building, on='building_id', how='left')\n",
    "train = train.merge(weather_train, on=['site_id', 'timestamp'], how='left')\n",
    "test = test.merge(weather_test, on=['site_id', 'timestamp'], how='left')\n",
    "\n",
    "del weather_train, weather_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvertToDatetime(TransformerMixin):\n",
    "        \n",
    "    def transform(self, df, **transform_params):\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "        return df\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogSquareFeet(TransformerMixin):\n",
    "        \n",
    "    def transform(self, df, **transform_params):\n",
    "        df['log_square_feet'] = np.float16(np.log(df['square_feet']))\n",
    "        return df\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SetCatTypes(TransformerMixin):\n",
    "        \n",
    "    def transform(self, df, **transform_params):\n",
    "        df['primary_use']= df['primary_use'].astype('category')\n",
    "        df['meter'] = df[\"meter\"].astype('category')\n",
    "        df['site_id'] = df[\"site_id\"].astype('category')\n",
    "        df['building_id'] = df['building_id'].astype('category')\n",
    "        return df\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImputeCloudCoverage(TransformerMixin):\n",
    "        \n",
    "    def transform(self, df, **transform_params):\n",
    "        # set age of building to mediam of site_id\n",
    "        # else if set ot overall median\n",
    "        median = df['cloud_coverage'].median()\n",
    "        # Set all year_built NaNs to site mean for year_built\n",
    "        for i, i_median in df.groupby(['site_id'])['cloud_coverage'].median().items():\n",
    "            if not np.isnan(i_median):\n",
    "                df.loc[(df['cloud_coverage'].isnull()) & (df['site_id'] == i), 'cloud_coverage'] = i_median\n",
    "            else:\n",
    "                df.loc[(df['cloud_coverage'].isnull()) & (df['site_id'] == i), 'cloud_coverage'] = median\n",
    "        df['cloud_coverage'] = np.uint8(df['cloud_coverage'])\n",
    "        df['cloud_coverage'] = df['cloud_coverage']\n",
    "        return df\n",
    "        \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CloudTimeCat(TransformerMixin):\n",
    "        \n",
    "    def transform(self, df, **transform_params):\n",
    "        tempDf = df[['cloud_coverage', 'hour']].astype('int')\n",
    "        tempDf['cloud_coverage'] = (tempDf['cloud_coverage']).astype('int')\n",
    "        tempDf['hour'] = (tempDf['hour']).astype('int')\n",
    "        tempDf = tempDf.astype('str')\n",
    "        df['cloud_time_cat'] = 'c' + tempDf['cloud_coverage'] + 't' + tempDf['hour']\n",
    "        df['cloud_time_cat'] = df['cloud_time_cat'].astype('category')\n",
    "        return df\n",
    "        \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropCols(TransformerMixin):\n",
    "\n",
    "    def __init__(self, drop_cols):\n",
    "        self._drop_cols = drop_cols\n",
    "        \n",
    "    def transform(self, df, **transform_params):\n",
    "        return df.drop(self._drop_cols, axis=1)\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImputeYearBuilt(TransformerMixin):\n",
    "\n",
    "    def transform(self, df, **transform_params):\n",
    "        year_built_median = df['year_built'].median()\n",
    "        # Set all year_built NaNs to site mean for year_built\n",
    "        for i, i_median in df.groupby(['site_id'])['year_built'].median().items():\n",
    "            if not np.isnan(i_median):\n",
    "                df.loc[(df['year_built'].isnull()) & (df['site_id'] == i), 'year_built'] = i_median\n",
    "            else:\n",
    "                df.loc[(df['year_built'].isnull()) & (df['site_id'] == i), 'year_built'] = year_built_median\n",
    "        df['building_age'] = np.uint8(df['year_built']-1900)\n",
    "        return df\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddMeterDummies(TransformerMixin):\n",
    "        \n",
    "    def transform(self, df_a, **transform_params):\n",
    "        df = df_a\n",
    "        for i in range(4):\n",
    "            df['_meter_'+str(i)] = (df['building_id'].isin(\n",
    "                train.loc[train['meter'] == i].building_id.unique()))\n",
    "        return df\n",
    "        \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddTimeFeatures(TransformerMixin):\n",
    "        \n",
    "    def transform(self, df_a, **transform_params):\n",
    "        df = df_a\n",
    "        df['dayofweek'] = df['timestamp'].dt.dayofweek.astype('category') # vs weekend?\n",
    "        #df['weekday'] = df['timestamp'].dt.weekday.astype('category')\n",
    "        #df['dayofweek_hour'] = (df['timestamp'].dt.dayofweek * 24) + df['timestamp'].dt.hour\n",
    "        #df['dayofweek_hour'] = df['dayofweek_hour'].astype('category')\n",
    "        #df['week'] = df['timestamp'].dt.week.astype('category')\n",
    "        df['hour'] = df['timestamp'].dt.hour.astype('category')\n",
    "        return df\n",
    "        \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddRelativeHumidity(TransformerMixin):\n",
    "        \n",
    "    def transform(self, df_a, **transform_params):\n",
    "        df = df_a\n",
    "        # code here\n",
    "        return df\n",
    "        \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FillMean(TransformerMixin):\n",
    "\n",
    "    def __init__(self, cols):\n",
    "        self._cols = cols\n",
    "        \n",
    "    def transform(self, df, **transform_params):\n",
    "        for col in self._cols:\n",
    "            df[col] = df[col].fillna(df[col].mean())\n",
    "        return df\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FillZeros(TransformerMixin):\n",
    "\n",
    "    def __init__(self, cols):\n",
    "        self._cols = cols\n",
    "        \n",
    "    def transform(self, df, **transform_params):\n",
    "        for col in self._cols:\n",
    "            df[col] = df[col].fillna(0)\n",
    "        return df\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FillMedian(TransformerMixin):\n",
    "\n",
    "    def __init__(self, cols):\n",
    "        self._cols = cols\n",
    "        \n",
    "    def transform(self, df, **transform_params):\n",
    "        for col in self._cols:\n",
    "            df[col] = df[col].fillna(df[col].median())\n",
    "        return df\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class FillPopular(TransformerMixin):\n",
    "\n",
    "    def __init__(self, cols):\n",
    "        self._cols = cols\n",
    "        \n",
    "    def transform(self, df, **transform_params):\n",
    "        for col in self._cols:\n",
    "            df[col] = df[col].fillna(df[col].value_counts()[0])\n",
    "        return df\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarkNaNs(TransformerMixin):\n",
    "        \n",
    "    def transform(self, df, **transform_params):\n",
    "        for col in  df.columns[df.isna().any()].tolist():\n",
    "            df['_' + col + '_nan' ] = df[col].isnull()\n",
    "        return df\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer, mean_squared_log_error, mean_squared_error\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "\n",
    "def rmsle(y, y_pred):\n",
    "    # hack to prevent negative numbers\n",
    "    return np.sqrt(mean_squared_log_error(y, y_pred.clip(0)))\n",
    "\n",
    "def rmse(y, y_pred):\n",
    "    # hack to prevent negative numbers\n",
    "    return mean_squared_error(y, y_pred.clip(0))\n",
    "\n",
    "def rmsee(y, y_pred):\n",
    "    # hack to prevent negative numbers\n",
    "    return np.sqrt(mean_squared_log_error(np.expm1(y.clip(0)), np.expm1(y_pred.clip(0))))\n",
    "    \n",
    "rmsle_scorer = make_scorer(\n",
    "    lambda y_true, y_pred : rmsle(y_true, y_pred), \n",
    "    greater_is_better=False)\n",
    "\n",
    "rmse_scorer = make_scorer(\n",
    "    lambda y_true, y_pred : rmsle(y_true, y_pred), \n",
    "    greater_is_better=False)\n",
    "\n",
    "rmsee_scorer = make_scorer(\n",
    "    lambda y_true, y_pred : rmsee(y_true, y_pred), \n",
    "    greater_is_better=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gbm=LGBMRegressor(n_estimators=500, # for accuracy use large numbers like 6000 \n",
    "                  learning_rate=0.1,\n",
    "                  feature_fraction=0.9,\n",
    "                  subsample=0.1,  # batches of 20% of the data\n",
    "                  subsample_freq=1,\n",
    "                  num_leaves=160,\n",
    "                  max_depth=10,\n",
    "                  metric='rmse',\n",
    "                  verbose= 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20216100, 18)\n",
      "(41697600, 18)\n",
      "         building_id meter           timestamp site_id  \\\n",
      "14245562        1324     1 2016-09-16 16:00:00      14   \n",
      "1282718         1013     0 2016-01-24 06:00:00      10   \n",
      "13883790         229     1 2016-09-10 07:00:00       2   \n",
      "4781820          217     3 2016-04-01 01:00:00       2   \n",
      "10415393        1434     0 2016-07-10 04:00:00      15   \n",
      "1057008         1047     0 2016-01-20 04:00:00      12   \n",
      "4507399          911     1 2016-03-26 20:00:00       9   \n",
      "19478829        1039     0 2016-12-18 23:00:00      12   \n",
      "8955615          265     0 2016-06-14 06:00:00       2   \n",
      "13799839         896     0 2016-09-08 19:00:00       9   \n",
      "15647011         973     0 2016-10-11 11:00:00       9   \n",
      "2524294          813     0 2016-02-16 08:00:00       8   \n",
      "10016102         870     0 2016-07-03 02:00:00       8   \n",
      "3915750          898     0 2016-03-15 03:00:00       9   \n",
      "17217526         903     0 2016-11-08 09:00:00       9   \n",
      "11478           1442     2 2016-01-01 04:00:00      15   \n",
      "18919011        1163     1 2016-12-09 02:00:00      13   \n",
      "8709341          371     0 2016-06-09 21:00:00       3   \n",
      "16313567         678     0 2016-10-23 07:00:00       5   \n",
      "6289526         1246     3 2016-04-27 20:00:00      14   \n",
      "\n",
      "                            primary_use  square_feet  year_built  floor_count  \\\n",
      "14245562  Entertainment/public assembly        84688         NaN          NaN   \n",
      "1282718                       Education        67377         NaN          3.0   \n",
      "13883790                      Education       140092         NaN          NaN   \n",
      "4781820                       Education       282946      2003.0          NaN   \n",
      "10415393                      Education        33148      1967.0          NaN   \n",
      "1057008                 Public services       252952         NaN          NaN   \n",
      "4507399                       Education       239638         NaN          NaN   \n",
      "19478829                      Education        30171         NaN          3.0   \n",
      "8955615                          Office       118966      1988.0          NaN   \n",
      "13799839                      Education       245637         NaN          NaN   \n",
      "15647011                         Office       193960         NaN          NaN   \n",
      "2524294                 Public services         5630         NaN          1.0   \n",
      "10016102  Entertainment/public assembly          755         NaN          1.0   \n",
      "3915750                 Public services        64749         NaN          NaN   \n",
      "17217526                      Education       275793         NaN          NaN   \n",
      "11478                   Public services        99541      1993.0          NaN   \n",
      "18919011                        Parking        83919         NaN          NaN   \n",
      "8709341   Entertainment/public assembly         5554         NaN          NaN   \n",
      "16313567                Public services        60977      1976.0          6.0   \n",
      "6289526                          Office        50327         NaN          NaN   \n",
      "\n",
      "          air_temperature  cloud_coverage  dew_temperature  precip_depth_1_hr  \\\n",
      "14245562        21.100000             3.0        10.000000                0.0   \n",
      "1282718          0.600000             7.0         0.000000                3.0   \n",
      "13883790        33.299999             4.0        13.300000                0.0   \n",
      "4781820         21.700001             5.0        -5.600000                0.0   \n",
      "10415393        19.400000             0.0        14.400000                2.6   \n",
      "1057008          1.700000             1.0         0.300000                NaN   \n",
      "4507399         22.799999             0.0        13.900000                0.0   \n",
      "19478829         6.300000             5.0         4.100000                NaN   \n",
      "8955615         30.600000             0.0         1.700000                0.0   \n",
      "13799839        33.900002             0.0        22.200001                0.0   \n",
      "15647011        13.300000             0.0         8.900000                0.0   \n",
      "2524294         19.400000             7.0        17.799999               10.0   \n",
      "10016102        24.400000             5.0        22.799999               -1.0   \n",
      "3915750         24.400000             0.0        15.000000                0.0   \n",
      "17217526        17.799999             4.0        17.200001               25.0   \n",
      "11478                 NaN             NaN              NaN                NaN   \n",
      "18919011        -6.100000             8.0       -11.700000               -1.0   \n",
      "8709341         27.799999             2.0         7.200000                0.0   \n",
      "16313567         7.000000             0.0         7.000000                NaN   \n",
      "6289526         12.200000             0.0         5.600000                0.0   \n",
      "\n",
      "          sea_level_pressure  wind_direction  wind_speed  log_square_feet  \\\n",
      "14245562         1026.099976           170.0        1.50        11.343750   \n",
      "1282718          1012.400024           160.0        4.10        11.117188   \n",
      "13883790         1009.599976           320.0        2.60        11.851562   \n",
      "4781820          1009.299988           240.0        5.70        12.554688   \n",
      "10415393         1010.099976           240.0        2.10        10.406250   \n",
      "1057008          1017.200012           130.0        3.00        12.437500   \n",
      "4507399          1012.000000           160.0        3.60        12.390625   \n",
      "19478829         1030.800049           200.0        5.00        10.312500   \n",
      "8955615          1008.299988             0.0        0.00        11.687500   \n",
      "13799839         1014.700012           166.0        2.85        12.414062   \n",
      "15647011         1019.500000             0.0        0.00        12.171875   \n",
      "2524294          1010.599976           190.0        5.10         8.632812   \n",
      "10016102         1019.099976           160.0        2.10         6.625000   \n",
      "3915750          1007.299988           210.0        1.50        11.078125   \n",
      "17217526         1019.400024           250.0        1.50        12.531250   \n",
      "11478                    NaN             NaN         NaN        11.507812   \n",
      "18919011         1033.699951           300.0        3.60        11.335938   \n",
      "8709341          1012.200012           310.0        4.60         8.625000   \n",
      "16313567                 NaN            70.0        7.20        11.015625   \n",
      "6289526          1011.799988           210.0        2.10        10.828125   \n",
      "\n",
      "         dayofweek hour  \n",
      "14245562         4   16  \n",
      "1282718          6    6  \n",
      "13883790         5    7  \n",
      "4781820          4    1  \n",
      "10415393         6    4  \n",
      "1057008          2    4  \n",
      "4507399          5   20  \n",
      "19478829         6   23  \n",
      "8955615          1    6  \n",
      "13799839         3   19  \n",
      "15647011         1   11  \n",
      "2524294          1    8  \n",
      "10016102         6    2  \n",
      "3915750          1    3  \n",
      "17217526         1    9  \n",
      "11478            4    4  \n",
      "18919011         4    2  \n",
      "8709341          3   21  \n",
      "16313567         6    7  \n",
      "6289526          2   20  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "352"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pre_a_pipes is for preprocessing that doesn't change impute\n",
    "# values\n",
    "pre_a_pipes = Pipeline(\n",
    "    steps=[\n",
    "        #('markNans',MarkNaNs()),\n",
    "        ('convertToDatetime', ConvertToDatetime()),\n",
    "        ('addRelativeHumidity',AddRelativeHumidity()),\n",
    "        ('logSquareFeet', LogSquareFeet()),\n",
    "        ('addTimeFeatures', AddTimeFeatures()),\n",
    "        ('setCatTypes', SetCatTypes()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_X = pre_a_pipes.transform(train.drop('meter_reading', axis=1))\n",
    "test_X = pre_a_pipes.transform(test.drop(['row_id'], axis=1))\n",
    "train_y = np.log1p(train['meter_reading'])\n",
    "\n",
    "print(train_X.shape)\n",
    "print(test_X.shape)\n",
    "print(train_X.sample(n=20,  random_state=42))\n",
    "\n",
    "del train, test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre_b_pipes is for imputed values and final\n",
    "# drops before modeling\n",
    "drop_cols = ['timestamp', 'square_feet',\n",
    "             'wind_direction',\n",
    "             'precip_depth_1_hr', \n",
    "             'year_built' ]\n",
    "fill_w_mean = ['floor_count','air_temperature','dew_temperature', \n",
    "              'precip_depth_1_hr', 'sea_level_pressure']\n",
    "fill_w_zero = []\n",
    "\n",
    "\n",
    "pre_b_pipes = Pipeline(\n",
    "    steps=[\n",
    "        ('fillMean',FillMean(fill_w_mean)),\n",
    "        ('fillZeros',FillZeros(fill_w_zero)),\n",
    "        ('imputeCloudCoverage', ImputeCloudCoverage()),\n",
    "        ('imputeYearBuilt', ImputeYearBuilt()),\n",
    "        ('dropClos', DropCols(drop_cols))\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe = Pipeline(\n",
    "    steps=[\n",
    "        ('pre_b_pipes',pre_b_pipes),\n",
    "        ('gbm', gbm)]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmsee scores:\n",
      " [-1.27741894 -1.22431268 -1.03063807 -1.16863322 -1.43158625]\n"
     ]
    }
   ],
   "source": [
    "# Cross val testing - can be skipped\n",
    "scores = cross_val_score(pipe, train_X, train_y, cv=5, \n",
    "                        scoring=rmsee_scorer)\n",
    "print('rmsee scores:\\n', scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del scores\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gbm__learning_rate': 0.1, 'gbm__max_depth': 10, 'gbm__n_estimators': 500, 'gbm__num_leaves': 160, 'gbm__subsample': 0.1}\n",
      "-1.355260118940074\n"
     ]
    }
   ],
   "source": [
    "# Grid param search - can be skpped\n",
    "grid_param = {\n",
    "    'gbm__n_estimators': [500],\n",
    "    'gbm__subsample': [0.1],\n",
    "    'gbm__learning_rate': [0.1],\n",
    "    'gbm__num_leaves': [80, 160],\n",
    "    'gbm__max_depth': [10]\n",
    "}\n",
    "\n",
    "gd_sr = GridSearchCV(pipe,\n",
    "                     param_grid=grid_param,\n",
    "                     scoring=rmsee_scorer,\n",
    "                     cv=3,\n",
    "                     n_jobs=-1)\n",
    "\n",
    "gd_sr.fit(train_X, train_y)\n",
    "\n",
    "best_parameters = gd_sr.best_params_\n",
    "print(best_parameters)\n",
    "best_result = gd_sr.best_score_\n",
    "print(best_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_fit_time  [1037.1145548  1219.01221228 2018.24647729 2310.51012079 3452.98459983\n",
      " 3756.19839891]\n",
      "std_fit_time  [31.04935087 17.90739042 32.56600359 10.7339371  58.70547761 28.39781594]\n",
      "mean_score_time  [ 952.49961909 1381.68596133 2672.66339318 4443.65559832 6902.2206138\n",
      " 8332.0504059 ]\n",
      "std_score_time  [ 37.48554732  14.36583429 212.15097066  24.25017769 548.62407352\n",
      "  93.30981057]\n",
      "param_gbm__learning_rate  [0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "param_gbm__max_depth  [10 10 10 10 10 10]\n",
      "param_gbm__n_estimators  [500 500 1000 1000 2000 2000]\n",
      "param_gbm__num_leaves  [80 160 80 160 80 160]\n",
      "param_gbm__subsample  [0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "params  [{'gbm__learning_rate': 0.1, 'gbm__max_depth': 10, 'gbm__n_estimators': 500, 'gbm__num_leaves': 80, 'gbm__subsample': 0.1}, {'gbm__learning_rate': 0.1, 'gbm__max_depth': 10, 'gbm__n_estimators': 500, 'gbm__num_leaves': 160, 'gbm__subsample': 0.1}, {'gbm__learning_rate': 0.1, 'gbm__max_depth': 10, 'gbm__n_estimators': 1000, 'gbm__num_leaves': 80, 'gbm__subsample': 0.1}, {'gbm__learning_rate': 0.1, 'gbm__max_depth': 10, 'gbm__n_estimators': 1000, 'gbm__num_leaves': 160, 'gbm__subsample': 0.1}, {'gbm__learning_rate': 0.1, 'gbm__max_depth': 10, 'gbm__n_estimators': 2000, 'gbm__num_leaves': 80, 'gbm__subsample': 0.1}, {'gbm__learning_rate': 0.1, 'gbm__max_depth': 10, 'gbm__n_estimators': 2000, 'gbm__num_leaves': 160, 'gbm__subsample': 0.1}]\n",
      "split0_test_score  [-1.51288162 -1.51159972 -1.51529644 -1.5179283  -1.51985798 -1.52358259]\n",
      "split1_test_score  [-1.130642   -1.12679824 -1.13079821 -1.13145342 -1.13353623 -1.13633013]\n",
      "split2_test_score  [-1.42527048 -1.4273824  -1.43004987 -1.43420768 -1.43789434 -1.44381625]\n",
      "mean_test_score  [-1.3562647  -1.35526012 -1.35871484 -1.36119646 -1.36376285 -1.36790966]\n",
      "std_test_score  [0.1634995  0.16516509 0.16487619 0.16600941 0.16619814 0.16695803]\n",
      "rank_test_score  [2 1 3 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "sorted(gd_sr.cv_results_.keys())\n",
    "for key in gd_sr.cv_results_.keys():\n",
    "    print(str(key) + \"  \" + str(gd_sr.cv_results_[key]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function gc.collect(generation=2)>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del gd_sr\n",
    "gc.collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('pre_b_pipes',\n",
       "                 Pipeline(memory=None,\n",
       "                          steps=[('fillMean',\n",
       "                                  <__main__.FillMean object at 0x000001F344830550>),\n",
       "                                 ('fillZeros',\n",
       "                                  <__main__.FillZeros object at 0x000001F34475E240>),\n",
       "                                 ('imputeCloudCoverage',\n",
       "                                  <__main__.ImputeCloudCoverage object at 0x000001F34475EEF0>),\n",
       "                                 ('imputeYearBuilt',\n",
       "                                  <__main__.ImputeYearBuilt object at 0x000001F3675A26A0>),\n",
       "                                 ('dro...\n",
       "                               colsample_bytree=1.0, feature_fraction=0.9,\n",
       "                               importance_type='split', learning_rate=0.1,\n",
       "                               max_depth=10, metric='rmse',\n",
       "                               min_child_samples=20, min_child_weight=0.001,\n",
       "                               min_split_gain=0.0, n_estimators=500, n_jobs=-1,\n",
       "                               num_leaves=160, objective=None,\n",
       "                               random_state=None, reg_alpha=0.0, reg_lambda=0.0,\n",
       "                               silent=True, subsample=0.1,\n",
       "                               subsample_for_bin=200000, subsample_freq=1,\n",
       "                               verbose=100))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit on all the data\n",
    "pipe.fit(train_X, train_y, \n",
    "         gbm__eval_metric=rmsee, gbm__verbose=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               feature  importance\n",
      "0          building_id       19164\n",
      "7      dew_temperature        9981\n",
      "5      air_temperature        9688\n",
      "12                hour        9598\n",
      "8   sea_level_pressure        9286\n",
      "1                meter        7346\n",
      "9           wind_speed        3567\n",
      "11           dayofweek        3106\n",
      "6       cloud_coverage        2718\n",
      "10     log_square_feet        2439\n",
      "2              site_id         876\n",
      "13        building_age         730\n",
      "4          floor_count         698\n",
      "3          primary_use         303\n",
      "['primary_use', 'floor_count', 'building_age', 'site_id', 'log_square_feet', 'cloud_coverage', 'dayofweek']\n"
     ]
    }
   ],
   "source": [
    "# Get features list for fit - can be skipped\n",
    "imprtc_df = pd.DataFrame()\n",
    "imprtc_df['feature'] = pre_b_pipes.transform(train_X).columns   \n",
    "imprtc_df['importance'] = pipe.named_steps['gbm'].feature_importances_\n",
    "imprtc_df.sort_values('importance', ascending=False, inplace= True)\n",
    "print(imprtc_df)\n",
    "print(imprtc_df.nsmallest(7,'importance')['feature'].tolist())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41697600 100 416976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|███████████████████████████████████████████████████████████████████████████▎     | 93/100 [14:12<01:20, 11.47s/it]"
     ]
    }
   ],
   "source": [
    "set_size = len(test_X)\n",
    "iterations = 100\n",
    "batch_size = set_size // iterations\n",
    "\n",
    "print(set_size, iterations, batch_size)\n",
    "assert set_size == iterations * batch_size\n",
    "\n",
    "meter_reading = []\n",
    "for i in tqdm(range(iterations)):\n",
    "    pos = i*batch_size\n",
    "    batch = np.expm1(pipe.predict(test_X.iloc[pos : pos+batch_size]).clip(0))\n",
    "    meter_reading.extend(batch)\n",
    "\n",
    "print(len(meter_reading))\n",
    "assert len(meter_reading) == set_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('../input/ashrae-energy-prediction/sample_submission.csv')\n",
    "# hack to prevent negative numbers\n",
    "print(sub.shape)\n",
    "sub['meter_reading'] = meter_reading\n",
    "sub.to_csv('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
