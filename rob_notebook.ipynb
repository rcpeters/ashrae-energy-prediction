{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "import pickle\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion, TransformerMixin\n",
    "import gc\n",
    "from os import path\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from pandas.core.dtypes.dtypes import CategoricalDtype\n",
    "from tqdm import tqdm\n",
    "from datetime import date \n",
    "import holidays\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "sns.set()\n",
    "%matplotlib inline\n",
    "\n",
    "# label encoding\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note you must run create-holiday-df notebook first to create the pickle\n",
    "holiday_df = pd.read_pickle('../input/ashrae-energy-prediction/holiday_df.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dtype = {\n",
    "    'train': {'building_id': np.int16, 'meter': np.int8, 'meter_reading': np.float32},\n",
    "    'test': {'building_id': np.int16, 'meter': np.int8},\n",
    "    'building_metadata': {'site_id': np.int8, 'building_id': np.uint16, 'square_feet': np.float16, 'year_built': np.float16, 'floor_count': np.float16},\n",
    "    'weather' : {'site_id': np.int8, 'air_temperature': np.float16, 'cloud_coverage': np.float16, 'dew_temperature': np.float16,\n",
    "                     'precip_depth_1_hr': np.float16, 'sea_level_pressure': np.float16, 'wind_direction': np.float16, 'wind_speed': np.float16}\n",
    "}\n",
    "\n",
    "file_loc = {}    \n",
    "for dir_path in ['../input/ashrae-energy-prediction/','../input/_ashrae-energy-prediction/']:\n",
    "    for name in ['building_metadata','weather_train','weather_test','train','test']:\n",
    "        if path.exists(dir_path + name + '.csv'):\n",
    "            file_loc[name]= dir_path + name + '.csv'\n",
    "    \n",
    "    building = pd.read_csv(file_loc['building_metadata'], dtype=file_dtype['building_metadata'])\n",
    "    weather_train = pd.read_csv(file_loc['weather_train'], dtype=file_dtype['weather'])\n",
    "    weather_test = pd.read_csv(file_loc['weather_test'], dtype=file_dtype['weather'])\n",
    "    train = pd.read_csv(file_loc['train'], dtype=file_dtype['train'])\n",
    "    test = pd.read_csv(file_loc['test'], dtype=file_dtype['test'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImputeWeather(TransformerMixin):\n",
    "\n",
    "    def __init__(self, method:str='linear', gap_limit:int=None, limit_direction:str='forward'):\n",
    "        self._method = method\n",
    "        self._gap_limit = gap_limit\n",
    "        self._limit_direction = limit_direction\n",
    "        \n",
    "    def transform(self, weather_df, **transform_params):\n",
    "        grouped_weather_df = weather_df.groupby('site_id').apply(lambda group: group.interpolate(method=self._method, limit=self._gap_limit, limit_direction=self._limit_direction))\n",
    "        if 'cloud_coverage' in grouped_weather_df.columns:\n",
    "            grouped_weather_df['cloud_coverage'] = grouped_weather_df['cloud_coverage'].round(decimals=0).clip(0,8)\n",
    "        grouped_weather_df.reset_index(inplace=True)\n",
    "        return grouped_weather_df.drop('index', axis=1)\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddWeatherLags(TransformerMixin):\n",
    "    \n",
    "    def __init__(self, window):\n",
    "        self._window = window\n",
    "        \n",
    "    def transform(self, weather_df, **transform_params):\n",
    "        group_df = weather_df.groupby(['site_id'])\n",
    "        cols = ['air_temperature', 'cloud_coverage', 'dew_temperature', 'precip_depth_1_hr', 'sea_level_pressure', 'wind_direction', 'wind_speed']\n",
    "        rolled = group_df[cols].rolling(window=self._window, min_periods=0)\n",
    "        lag_mean = rolled.mean().reset_index().astype(np.float16)\n",
    "        lag_max = rolled.max().reset_index().astype(np.float16)\n",
    "        lag_min = rolled.min().reset_index().astype(np.float16)\n",
    "        lag_std = rolled.std().reset_index().astype(np.float16)\n",
    "        for col in cols:\n",
    "            weather_df[f'{col}_mean_lag{self._window}'] = lag_mean[col]\n",
    "            weather_df[f'{col}_max_lag{self._window}'] = lag_max[col]\n",
    "            weather_df[f'{col}_min_lag{self._window}'] = lag_min[col]\n",
    "            weather_df[f'{col}_std_lag{self._window}'] = lag_std[col]\n",
    "        return weather_df\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddWeather(TransformerMixin):\n",
    "\n",
    "    def __init__(self, weather_df):\n",
    "        self._b_df = weather_df\n",
    "        \n",
    "    def transform(self, df, **transform_params):\n",
    "        \n",
    "        return df.merge(weather_test, on=['site_id', 'timestamp'], how='left')\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddBuilding(TransformerMixin):\n",
    "\n",
    "    def __init__(self, building_df):\n",
    "        self._b_df = building_df\n",
    "        \n",
    "    def transform(self, df, **transform_params):\n",
    "        \n",
    "        return df.merge(_b_df, on='building_id', how='left')\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvertToDatetime(TransformerMixin):\n",
    "        \n",
    "    def transform(self, df, **transform_params):\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "        return df\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_us = [0,2,3,4,6,8,9,10,13,14]\n",
    "in_ca = [7,11]\n",
    "in_uk = [1,5]\n",
    "in_ie = [12]\n",
    "us_cal =  holidays.US()\n",
    "ca_cal = holidays.CA()\n",
    "ie_cal = holidays.IE()\n",
    "uk_cal = holidays.UK()\n",
    "\n",
    "def holidayName(timestamp, site_id):\n",
    "    if site_id in in_ca:\n",
    "        return ca_cal.get(timestamp)\n",
    "    elif site_id in in_uk:\n",
    "        return uk_cal.get(timestamp)\n",
    "    elif site_id in in_ie:\n",
    "        return ie_cal.get(timestamp)\n",
    "    else:\n",
    "        return us_cal.get(timestamp)\n",
    "    \n",
    "# https://www.kaggle.com/c/ashrae-energy-prediction/discussion/114483#latest-660771\n",
    "# https://www.kaggle.com/c/ashrae-energy-prediction/discussion/114874#latest-660970\n",
    "class AddHolidays(TransformerMixin):\n",
    "    def transform(self, df, **transform_params):\n",
    "        df = df.merge(holiday_df, on=['building_id','meter','timestamp','site_id'], how='left')\n",
    "        return df\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "# Test \n",
    "addHolidays = AddHolidays()\n",
    "print(addHolidays.transform(train.head(2000).merge(building, on='building_id', how='left'))[['building_id','timestamp','holiday']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RmHolidays(TransformerMixin):\n",
    "    def transform(self, df, **transform_params):\n",
    "        #df['holiday'] = df.apply(lambda x: all_holidays.get(x))\n",
    "        #df['holiday'] = df.apply(lambda x: holidayName(x.timestamp, x.site_id))\n",
    "        #print(temp_df['holiday'].notnull())\n",
    "        df = df.merge(holiday_df, on=['building_id','meter','timestamp','site_id'], how='left')\n",
    "        df = df.drop(df[df['holiday'].notnull()].index)\n",
    "        df = df.drop(['holiday'], axis=1)\n",
    "        return df\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "# Test \n",
    "rmHolidays = RmHolidays()\n",
    "print(rmHolidays.transform(train.head(100000).merge(building, on='building_id', how='left'))[['building_id','timestamp']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogSquareFeet(TransformerMixin):\n",
    "        \n",
    "    def transform(self, df, **transform_params):\n",
    "        df['log_square_feet'] = np.float16(np.log(df['square_feet']))\n",
    "        return df\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SetCatTypes(TransformerMixin):\n",
    "        \n",
    "    def transform(self, df, **transform_params):\n",
    "        df['primary_use']= df['primary_use'].astype('category')\n",
    "        df['meter'] = df[\"meter\"].astype('category')\n",
    "        df['site_id'] = df[\"site_id\"].astype('category')\n",
    "        df['building_id'] = df['building_id'].astype('category')\n",
    "        return df\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImputeCloudCoverage(TransformerMixin):\n",
    "        \n",
    "    def transform(self, df, **transform_params):\n",
    "        # set age of building to mediam of site_id\n",
    "        # else if set ot overall median\n",
    "        median = df['cloud_coverage'].median()\n",
    "        # Set all year_built NaNs to site mean for year_built\n",
    "        for i, i_median in df.groupby(['site_id'])['cloud_coverage'].median().items():\n",
    "            if not np.isnan(i_median):\n",
    "                df.loc[(df['cloud_coverage'].isnull()) & (df['site_id'] == i), 'cloud_coverage'] = i_median\n",
    "            else:\n",
    "                df.loc[(df['cloud_coverage'].isnull()) & (df['site_id'] == i), 'cloud_coverage'] = median\n",
    "        df['cloud_coverage'] = np.uint8(df['cloud_coverage'])\n",
    "        df['cloud_coverage'] = df['cloud_coverage']\n",
    "        return df\n",
    "        \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CloudTimeCat(TransformerMixin):\n",
    "        \n",
    "    def transform(self, df, **transform_params):\n",
    "        tempDf = df[['cloud_coverage', 'hour']].astype('int')\n",
    "        tempDf['cloud_coverage'] = (tempDf['cloud_coverage']).astype('int')\n",
    "        tempDf['hour'] = (tempDf['hour']).astype('int')\n",
    "        tempDf = tempDf.astype('str')\n",
    "        df['cloud_time_cat'] = 'c' + tempDf['cloud_coverage'] + 't' + tempDf['hour']\n",
    "        df['cloud_time_cat'] = df['cloud_time_cat'].astype('category')\n",
    "        return df\n",
    "        \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropCols(TransformerMixin):\n",
    "\n",
    "    def __init__(self, drop_cols):\n",
    "        self._drop_cols = drop_cols\n",
    "        \n",
    "    def transform(self, df, **transform_params):\n",
    "        return df.drop(self._drop_cols, axis=1)\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImputeYearBuilt(TransformerMixin):\n",
    "\n",
    "    def transform(self, df, **transform_params):\n",
    "        year_built_median = df['year_built'].median()\n",
    "        # Set all year_built NaNs to site mean for year_built\n",
    "        for i, i_median in df.groupby(['site_id'])['year_built'].median().items():\n",
    "            if not np.isnan(i_median):\n",
    "                df.loc[(df['year_built'].isnull()) & (df['site_id'] == i), 'year_built'] = i_median\n",
    "            else:\n",
    "                df.loc[(df['year_built'].isnull()) & (df['site_id'] == i), 'year_built'] = year_built_median\n",
    "        df['building_age'] = np.uint8(df['year_built']-1900)\n",
    "        return df\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddMeterDummies(TransformerMixin):\n",
    "        \n",
    "    def transform(self, df_a, **transform_params):\n",
    "        df = df_a\n",
    "        for i in range(4):\n",
    "            df['_meter_'+str(i)] = (df['building_id'].isin(\n",
    "                train.loc[train['meter'] == i].building_id.unique()))\n",
    "        return df\n",
    "        \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddTimeFeatures(TransformerMixin):\n",
    "        \n",
    "    def transform(self, df_a, **transform_params):\n",
    "        df = df_a\n",
    "        df['dayofweek'] = df['timestamp'].dt.dayofweek.astype('category') # vs weekend?\n",
    "        #df['weekday'] = df['timestamp'].dt.weekday.astype('category')\n",
    "        #df['dayofweek_hour'] = (df['timestamp'].dt.dayofweek * 24) + df['timestamp'].dt.hour\n",
    "        #df['dayofweek_hour'] = df['dayofweek_hour'].astype('category')\n",
    "        #df['week'] = df['timestamp'].dt.week.astype('category')\n",
    "        df['hour'] = df['timestamp'].dt.hour.astype('category')\n",
    "        return df\n",
    "        \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddRelativeHumidity(TransformerMixin):\n",
    "        \n",
    "    def transform(self, df_a, **transform_params):\n",
    "        df = df_a\n",
    "        # code here\n",
    "        return df\n",
    "        \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FillMean(TransformerMixin):\n",
    "\n",
    "    def __init__(self, cols):\n",
    "        self._cols = cols\n",
    "        \n",
    "    def transform(self, df, **transform_params):\n",
    "        for col in self._cols:\n",
    "            df[col] = df[col].fillna(df[col].mean())\n",
    "        return df\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FillZeros(TransformerMixin):\n",
    "\n",
    "    def __init__(self, cols):\n",
    "        self._cols = cols\n",
    "        \n",
    "    def transform(self, df, **transform_params):\n",
    "        for col in self._cols:\n",
    "            df[col] = df[col].fillna(0)\n",
    "        return df\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FillMedian(TransformerMixin):\n",
    "\n",
    "    def __init__(self, cols):\n",
    "        self._cols = cols\n",
    "        \n",
    "    def transform(self, df, **transform_params):\n",
    "        for col in self._cols:\n",
    "            df[col] = df[col].fillna(df[col].median())\n",
    "        return df\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class FillPopular(TransformerMixin):\n",
    "\n",
    "    def __init__(self, cols):\n",
    "        self._cols = cols\n",
    "        \n",
    "    def transform(self, df, **transform_params):\n",
    "        for col in self._cols:\n",
    "            df[col] = df[col].fillna(df[col].value_counts()[0])\n",
    "        return df\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarkNaNs(TransformerMixin):\n",
    "        \n",
    "    def transform(self, df, **transform_params):\n",
    "        for col in  df.columns[df.isna().any()].tolist():\n",
    "            df['_' + col + '_nan' ] = df[col].isnull()\n",
    "        return df\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GC(TransformerMixin):\n",
    "        \n",
    "    def transform(self, df, **transform_params):\n",
    "        gc.collect()\n",
    "        return df\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer, mean_squared_log_error, mean_squared_error\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "\n",
    "def rmsle(y, y_pred):\n",
    "    # hack to prevent negative numbers\n",
    "    return np.sqrt(mean_squared_log_error(y, y_pred.clip(0)))\n",
    "\n",
    "def rmse(y, y_pred):\n",
    "    # hack to prevent negative numbers\n",
    "    return mean_squared_error(y, y_pred.clip(0))\n",
    "\n",
    "def rmsee(y, y_pred):\n",
    "    # hack to prevent negative numbers\n",
    "    return np.sqrt(mean_squared_log_error(np.expm1(y.clip(0)), np.expm1(y_pred.clip(0))))\n",
    "    \n",
    "rmsle_scorer = make_scorer(\n",
    "    lambda y_true, y_pred : rmsle(y_true, y_pred), \n",
    "    greater_is_better=False)\n",
    "\n",
    "rmse_scorer = make_scorer(\n",
    "    lambda y_true, y_pred : rmsle(y_true, y_pred), \n",
    "    greater_is_better=False)\n",
    "\n",
    "rmsee_scorer = make_scorer(\n",
    "    lambda y_true, y_pred : rmsee(y_true, y_pred), \n",
    "    greater_is_better=False)\n",
    "\n",
    "def lbm_rmsle(y_true, y_pred):\n",
    "    return 'RMSLE', np.sqrt(np.mean(np.power(np.log1p(y_pred) - np.log1p(y_true), 2))), False\n",
    "\n",
    "# rob's custome function to do RMSLE while in the log1p space\n",
    "def lbm_rmslee(y_true, y_pred):\n",
    "    return 'RMSLEE', np.sqrt(np.mean(np.power(y_pred - y_true, 2))), False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_pipes = Pipeline(\n",
    "    steps=[\n",
    "        ('imputeWeather', ImputeWeather()),\n",
    "        ('fillMean',FillMean(['air_temperature','dew_temperature'\n",
    "                              , 'precip_depth_1_hr', 'sea_level_pressure'])),\n",
    "        ('imputeCloudCoverage', ImputeCloudCoverage()),\n",
    "        ('addWeatherLags3', AddWeatherLags(3)),\n",
    "        ('addWeatherLags72', AddWeatherLags(72)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "building_pipes = Pipeline(\n",
    "    steps=[\n",
    "        ('logSquareFeet', LogSquareFeet()),\n",
    "        ('imputeYearBuilt', ImputeYearBuilt()),\n",
    "        ('fillMean',FillMean(['floor_count'])),\n",
    "        ('dropClos', DropCols(['square_feet', 'year_built'])),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# pre_a_pipes is for preprocessing that doesn't change impute\n",
    "# values\n",
    "x_pipes = Pipeline(\n",
    "    steps=[\n",
    "        #('markNans',MarkNaNs()),\n",
    "        ('convertToDatetime', ConvertToDatetime()),\n",
    "        #('addHolidays', AddHolidays()),\n",
    "        #('rmHolidays', RmHolidays()),\n",
    "        ('addRelativeHumidity',AddRelativeHumidity()),\n",
    "        ('addTimeFeatures', AddTimeFeatures()),\n",
    "        ('setCatTypes', SetCatTypes()),\n",
    "        ('fillMean',FillMean([])),\n",
    "        ('fillZeros',FillZeros([])),\n",
    "        ('dropClos', DropCols(['timestamp'])),\n",
    "        ('GC', GC())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_X = x_pipes.transform(\n",
    "    test\n",
    "        .merge(building_pipes.transform(building), on='building_id', how='left').drop(['row_id'], axis=1)\n",
    "        .merge(weather_pipes.transform(weather_test), on=['site_id', 'timestamp'], how='left')\n",
    "    )\n",
    "\n",
    "print(test_X.sample(n=20,  random_state=42))\n",
    "print(test_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOutsideFoldXY(train_index):\n",
    "    X = train.iloc[train_index].drop('meter_reading', axis=1)\n",
    "    X_buildings = building[building['building_id'].isin(X['building_id'].unique())]\n",
    "    X_weather = building[building['building_id'].isin(X['building_id'].unique())]\n",
    "    X = x_pipes.transform(\n",
    "        X\n",
    "            .merge(building_pipes.transform(X_buildings), on='building_id', how='left')\n",
    "            .merge(weather_train_trans, on=['site_id', 'timestamp'], how='left')\n",
    "        )\n",
    "    f_train_y = np.log1p(train.iloc[train_index]['meter_reading'])\n",
    "    print(X.columns)\n",
    "    return X,f_train_y\n",
    "\n",
    "\n",
    "\n",
    "def getInFoldXY(train_index):\n",
    "    X = train.iloc[train_index]\n",
    "    X_buildings = building[building['building_id'].isin(X['building_id'].unique())]\n",
    "    X = X.merge(building_pipes.transform(X_buildings), on='building_id', how='left')\n",
    "    X_weather = weather_train[\n",
    "        (weather_train['site_id'].isin(X['site_id'].unique())) \n",
    "         & (weather_train['timestamp'].isin(X['timestamp'].unique())) \n",
    "    ]\n",
    "    X = x_pipes.transform(\n",
    "        rmHolidays.transform(\n",
    "            X.merge(weather_pipes.transform(X_weather), how='left')))\n",
    "    return X.drop('meter_reading', axis=1),  np.log1p(X['meter_reading'])\n",
    "\n",
    "\n",
    "print(getInFoldXY(train.head(10).index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_params = {\n",
    "    'n_estimators' : 500, # for accuracy use large numbers like 6000 \n",
    "    'learning_rate': 0.4,\n",
    "    'feature_fraction' : 0.9,\n",
    "    'subsample' : 0.1,  # \n",
    "    'subsample_freq' : 1,\n",
    "    'num_leaves' : 20,\n",
    "    'max_depth' : 10,\n",
    "    'metric':'rmse',\n",
    "    'lambda_l1' : 1,  \n",
    "    'lambda_l2': 1,\n",
    "    'verbose': 100\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "folds = 5\n",
    "\n",
    "# this stratified strategy from\n",
    "# https://www.kaggle.com/isaienkov/lightgbm-fe-1-19/notebook\n",
    "kf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "\n",
    "models = []\n",
    "best_scores = []\n",
    "for train_index, val_index in kf.split(train, train['building_id']):\n",
    "    f_train_X, f_train_y = getInFoldXY(train_index)\n",
    "    f_val_X, f_val_y = getInFoldXY(val_index)\n",
    "    gbm = LGBMRegressor(**gbm_params)\n",
    "    gbm.fit(f_train_X, f_train_y,\n",
    "        eval_set=[(f_val_X, f_val_y)],\n",
    "        # https://www.kaggle.com/c/ashrae-energy-prediction/discussion/114722#latest-660848\n",
    "        # eval_metric=lbm_rmslee,\n",
    "        early_stopping_rounds=20)\n",
    "    models.append(gbm)\n",
    "    #y_pred = gbm.predict(f_val_X, num_iteration=gbm.best_iteration_)\n",
    "    # eval\n",
    "    #rmsle_score = lbm_rmslee(f_val_X, y_pred)[1]\n",
    "    best_scores.append(gbm.best_score_)\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for score in best_scores:\n",
    "    print(score['valid_0']['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "imprtc_df = pd.DataFrame()\n",
    "imprtc_df['feature'] = test_X.columns   \n",
    "imprtc_df['importance'] = models[0].feature_importances_\n",
    "imprtc_df.sort_values('importance', ascending=False, inplace= True)\n",
    "print(imprtc_df)\n",
    "print(test_X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "# Cross val models ensemble \n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i=0\n",
    "res=[]\n",
    "step_size = 50000\n",
    "for j in tqdm(range(int(np.ceil(test_X.shape[0]/50000)))):\n",
    "    res.append(np.expm1(sum([model.predict(test_X.iloc[i:i+step_size]) for model in models])/folds))\n",
    "    #res.append(np.expm1(gbm.predict(test_X.iloc[i:i+step_size])))\n",
    "    i+=step_size\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = np.concatenate(res)\n",
    "print(len(res))\n",
    "submission = pd.read_csv('../input/ashrae-energy-prediction/sample_submission.csv')\n",
    "submission['meter_reading'] = res\n",
    "submission.loc[submission['meter_reading']<0, 'meter_reading'] = 0\n",
    "submission.to_csv('submission.csv.zip', index=False)\n",
    "submission.sample(n=20,  random_state=42))\n",
    "submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "# Single model fit\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "gbm = LGBMRegressor(**gbm_params)\n",
    "f_train_X, f_train_y = getInFoldXY(train.index)\n",
    "gbm.fit(f_train_X, f_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "res=[]\n",
    "step_size = 50000\n",
    "for j in tqdm(range(int(np.ceil(test_X.shape[0]/50000)))):\n",
    "    res.append(np.expm1(sum([model.predict(test_X.iloc[i:i+step_size]) for model in models])/folds))\n",
    "    #res.append(np.expm1(gbm.predict(test_X.iloc[i:i+step_size])))\n",
    "    i+=step_size\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
