{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "import pickle\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion, TransformerMixin\n",
    "import gc\n",
    "from os import path\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from pandas.core.dtypes.dtypes import CategoricalDtype\n",
    "from tqdm import tqdm\n",
    "from datetime import date \n",
    "import holidays\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "sns.set()\n",
    "%matplotlib inline\n",
    "\n",
    "# label encoding\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dtype = {\n",
    "    'train': {'building_id': np.int16, 'meter': np.int8, 'meter_reading': np.float32},\n",
    "    'test': {'building_id': np.int16, 'meter': np.int8},\n",
    "    'building_metadata': {'site_id': np.int8, 'building_id': np.uint16, 'square_feet': np.float16, 'year_built': np.float16, 'floor_count': np.float16},\n",
    "    'weather' : {'site_id': np.int8, 'air_temperature': np.float16, 'cloud_coverage': np.float16, 'dew_temperature': np.float16,\n",
    "                     'precip_depth_1_hr': np.float16, 'sea_level_pressure': np.float16, 'wind_direction': np.float16, 'wind_speed': np.float16}\n",
    "}\n",
    "\n",
    "file_loc = {}    \n",
    "for dir_path in ['../input/ashrae-energy-prediction/','../input/_ashrae-energy-prediction/']:\n",
    "    for name in ['building_metadata','weather_train','weather_test','train','test']:\n",
    "        if path.exists(dir_path + name + '.csv'):\n",
    "            file_loc[name]= dir_path + name + '.csv'\n",
    "    \n",
    "    building = pd.read_csv(file_loc['building_metadata'], dtype=file_dtype['building_metadata'])\n",
    "    weather_train = pd.read_csv(file_loc['weather_train'], dtype=file_dtype['weather'])\n",
    "    weather_test = pd.read_csv(file_loc['weather_test'], dtype=file_dtype['weather'])\n",
    "    train = pd.read_csv(file_loc['train'], dtype=file_dtype['train'])\n",
    "    test = pd.read_csv(file_loc['test'], dtype=file_dtype['test'])\n",
    "    \n",
    "holiday_df = pd.read_pickle('../input/ashrae-energy-prediction/holiday_df.pickle')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImputeWeather(TransformerMixin):\n",
    "\n",
    "    def __init__(self, method:str='linear', gap_limit:int=None, limit_direction:str='forward'):\n",
    "        self._method = method\n",
    "        self._gap_limit = gap_limit\n",
    "        self._limit_direction = limit_direction\n",
    "        \n",
    "    def transform(self, weather_df, **transform_params):\n",
    "        grouped_weather_df = weather_df.groupby('site_id').apply(lambda group: group.interpolate(method=self._method, limit=self._gap_limit, limit_direction=self._limit_direction))\n",
    "        if 'cloud_coverage' in grouped_weather_df.columns:\n",
    "            grouped_weather_df['cloud_coverage'] = grouped_weather_df['cloud_coverage'].round(decimals=0).clip(0,8)\n",
    "        grouped_weather_df.reset_index(inplace=True)\n",
    "        return grouped_weather_df.drop('index', axis=1)\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddWeatherLags(TransformerMixin):\n",
    "    \n",
    "    def __init__(self, window):\n",
    "        self._window = window\n",
    "        \n",
    "    def transform(self, weather_df, **transform_params):\n",
    "        group_df = weather_df.groupby(['site_id'])\n",
    "        cols = ['air_temperature', 'cloud_coverage', 'dew_temperature', 'precip_depth_1_hr', 'sea_level_pressure', 'wind_direction', 'wind_speed']\n",
    "        rolled = group_df[cols].rolling(window=self._window, min_periods=0)\n",
    "        lag_mean = rolled.mean().reset_index().astype(np.float16)\n",
    "        lag_max = rolled.max().reset_index().astype(np.float16)\n",
    "        lag_min = rolled.min().reset_index().astype(np.float16)\n",
    "        lag_std = rolled.std().reset_index().astype(np.float16)\n",
    "        for col in cols:\n",
    "            weather_df[f'{col}_mean_lag{self._window}'] = lag_mean[col]\n",
    "            weather_df[f'{col}_max_lag{self._window}'] = lag_max[col]\n",
    "            weather_df[f'{col}_min_lag{self._window}'] = lag_min[col]\n",
    "            weather_df[f'{col}_std_lag{self._window}'] = lag_std[col]\n",
    "        return weather_df\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddWeather(TransformerMixin):\n",
    "\n",
    "    def __init__(self, weather_df):\n",
    "        self._b_df = weather_df\n",
    "        \n",
    "    def transform(self, df, **transform_params):\n",
    "        \n",
    "        return df.merge(weather_test, on=['site_id', 'timestamp'], how='left')\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddBuilding(TransformerMixin):\n",
    "\n",
    "    def __init__(self, building_df):\n",
    "        self._b_df = building_df\n",
    "        \n",
    "    def transform(self, df, **transform_params):\n",
    "        \n",
    "        return df.merge(_b_df, on='building_id', how='left')\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvertToDatetime(TransformerMixin):\n",
    "        \n",
    "    def transform(self, df, **transform_params):\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "        return df\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      building_id            timestamp         holiday\n",
      "0               0  2016-01-01 00:00:00  New Year's Day\n",
      "1               1  2016-01-01 00:00:00  New Year's Day\n",
      "2               2  2016-01-01 00:00:00  New Year's Day\n",
      "3               3  2016-01-01 00:00:00  New Year's Day\n",
      "4               4  2016-01-01 00:00:00  New Year's Day\n",
      "5               5  2016-01-01 00:00:00  New Year's Day\n",
      "6               6  2016-01-01 00:00:00  New Year's Day\n",
      "7               7  2016-01-01 00:00:00  New Year's Day\n",
      "8               8  2016-01-01 00:00:00  New Year's Day\n",
      "9               9  2016-01-01 00:00:00  New Year's Day\n",
      "10             10  2016-01-01 00:00:00  New Year's Day\n",
      "11             11  2016-01-01 00:00:00  New Year's Day\n",
      "12             12  2016-01-01 00:00:00  New Year's Day\n",
      "13             13  2016-01-01 00:00:00  New Year's Day\n",
      "14             14  2016-01-01 00:00:00  New Year's Day\n",
      "15             15  2016-01-01 00:00:00  New Year's Day\n",
      "16             16  2016-01-01 00:00:00  New Year's Day\n",
      "17             17  2016-01-01 00:00:00  New Year's Day\n",
      "18             18  2016-01-01 00:00:00  New Year's Day\n",
      "19             19  2016-01-01 00:00:00  New Year's Day\n",
      "20             20  2016-01-01 00:00:00  New Year's Day\n",
      "21             21  2016-01-01 00:00:00  New Year's Day\n",
      "22             22  2016-01-01 00:00:00  New Year's Day\n",
      "23             23  2016-01-01 00:00:00  New Year's Day\n",
      "24             24  2016-01-01 00:00:00  New Year's Day\n",
      "25             25  2016-01-01 00:00:00  New Year's Day\n",
      "26             26  2016-01-01 00:00:00  New Year's Day\n",
      "27             27  2016-01-01 00:00:00  New Year's Day\n",
      "28             28  2016-01-01 00:00:00  New Year's Day\n",
      "29             30  2016-01-01 00:00:00  New Year's Day\n",
      "...           ...                  ...             ...\n",
      "1970         1292  2016-01-01 00:00:00  New Year's Day\n",
      "1971         1292  2016-01-01 00:00:00  New Year's Day\n",
      "1972         1292  2016-01-01 00:00:00  New Year's Day\n",
      "1973         1293  2016-01-01 00:00:00  New Year's Day\n",
      "1974         1293  2016-01-01 00:00:00  New Year's Day\n",
      "1975         1293  2016-01-01 00:00:00  New Year's Day\n",
      "1976         1293  2016-01-01 00:00:00  New Year's Day\n",
      "1977         1294  2016-01-01 00:00:00  New Year's Day\n",
      "1978         1294  2016-01-01 00:00:00  New Year's Day\n",
      "1979         1294  2016-01-01 00:00:00  New Year's Day\n",
      "1980         1294  2016-01-01 00:00:00  New Year's Day\n",
      "1981         1295  2016-01-01 00:00:00  New Year's Day\n",
      "1982         1295  2016-01-01 00:00:00  New Year's Day\n",
      "1983         1295  2016-01-01 00:00:00  New Year's Day\n",
      "1984         1295  2016-01-01 00:00:00  New Year's Day\n",
      "1985         1296  2016-01-01 00:00:00  New Year's Day\n",
      "1986         1296  2016-01-01 00:00:00  New Year's Day\n",
      "1987         1296  2016-01-01 00:00:00  New Year's Day\n",
      "1988         1296  2016-01-01 00:00:00  New Year's Day\n",
      "1989         1297  2016-01-01 00:00:00  New Year's Day\n",
      "1990         1297  2016-01-01 00:00:00  New Year's Day\n",
      "1991         1297  2016-01-01 00:00:00  New Year's Day\n",
      "1992         1297  2016-01-01 00:00:00  New Year's Day\n",
      "1993         1298  2016-01-01 00:00:00  New Year's Day\n",
      "1994         1298  2016-01-01 00:00:00  New Year's Day\n",
      "1995         1298  2016-01-01 00:00:00  New Year's Day\n",
      "1996         1298  2016-01-01 00:00:00  New Year's Day\n",
      "1997         1299  2016-01-01 00:00:00  New Year's Day\n",
      "1998         1299  2016-01-01 00:00:00  New Year's Day\n",
      "1999         1299  2016-01-01 00:00:00  New Year's Day\n",
      "\n",
      "[2000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "in_us = [0,2,3,4,6,8,9,10,13,14]\n",
    "in_ca = [7,11]\n",
    "in_uk = [1,5]\n",
    "in_ie = [12]\n",
    "us_cal =  holidays.US()\n",
    "ca_cal = holidays.CA()\n",
    "ie_cal = holidays.IE()\n",
    "uk_cal = holidays.UK()\n",
    "\n",
    "def holidayName(timestamp, site_id):\n",
    "    if site_id in in_ca:\n",
    "        return ca_cal.get(timestamp)\n",
    "    elif site_id in in_uk:\n",
    "        return uk_cal.get(timestamp)\n",
    "    elif site_id in in_ie:\n",
    "        return ie_cal.get(timestamp)\n",
    "    else:\n",
    "        return us_cal.get(timestamp)\n",
    "    \n",
    "# https://www.kaggle.com/c/ashrae-energy-prediction/discussion/114483#latest-660771\n",
    "# https://www.kaggle.com/c/ashrae-energy-prediction/discussion/114874#latest-660970\n",
    "class AddHolidays(TransformerMixin):\n",
    "    def transform(self, df, **transform_params):\n",
    "        df = df.merge(holiday_df, on=['building_id','meter','timestamp','site_id'], how='left')\n",
    "        return df\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "# Test \n",
    "addHolidays = AddHolidays()\n",
    "print(addHolidays.transform(train.head(2000).merge(building, on='building_id', how='left'))[['building_id','timestamp','holiday']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       building_id            timestamp\n",
      "55121            0  2016-01-02 00:00:00\n",
      "55122            1  2016-01-02 00:00:00\n",
      "55123            2  2016-01-02 00:00:00\n",
      "55124            3  2016-01-02 00:00:00\n",
      "55125            4  2016-01-02 00:00:00\n",
      "55126            5  2016-01-02 00:00:00\n",
      "55127            6  2016-01-02 00:00:00\n",
      "55128            7  2016-01-02 00:00:00\n",
      "55129            8  2016-01-02 00:00:00\n",
      "55130            9  2016-01-02 00:00:00\n",
      "55131           10  2016-01-02 00:00:00\n",
      "55132           11  2016-01-02 00:00:00\n",
      "55133           12  2016-01-02 00:00:00\n",
      "55134           13  2016-01-02 00:00:00\n",
      "55135           14  2016-01-02 00:00:00\n",
      "55136           15  2016-01-02 00:00:00\n",
      "55137           16  2016-01-02 00:00:00\n",
      "55138           17  2016-01-02 00:00:00\n",
      "55139           18  2016-01-02 00:00:00\n",
      "55140           19  2016-01-02 00:00:00\n",
      "55141           20  2016-01-02 00:00:00\n",
      "55142           21  2016-01-02 00:00:00\n",
      "55143           22  2016-01-02 00:00:00\n",
      "55144           23  2016-01-02 00:00:00\n",
      "55145           24  2016-01-02 00:00:00\n",
      "55146           25  2016-01-02 00:00:00\n",
      "55147           26  2016-01-02 00:00:00\n",
      "55148           27  2016-01-02 00:00:00\n",
      "55149           28  2016-01-02 00:00:00\n",
      "55150           30  2016-01-02 00:00:00\n",
      "...            ...                  ...\n",
      "99970          922  2016-01-02 19:00:00\n",
      "99971          922  2016-01-02 19:00:00\n",
      "99972          922  2016-01-02 19:00:00\n",
      "99973          923  2016-01-02 19:00:00\n",
      "99974          923  2016-01-02 19:00:00\n",
      "99975          924  2016-01-02 19:00:00\n",
      "99976          924  2016-01-02 19:00:00\n",
      "99977          924  2016-01-02 19:00:00\n",
      "99978          925  2016-01-02 19:00:00\n",
      "99979          925  2016-01-02 19:00:00\n",
      "99980          925  2016-01-02 19:00:00\n",
      "99981          926  2016-01-02 19:00:00\n",
      "99982          926  2016-01-02 19:00:00\n",
      "99983          926  2016-01-02 19:00:00\n",
      "99984          927  2016-01-02 19:00:00\n",
      "99985          927  2016-01-02 19:00:00\n",
      "99986          927  2016-01-02 19:00:00\n",
      "99987          928  2016-01-02 19:00:00\n",
      "99988          928  2016-01-02 19:00:00\n",
      "99989          928  2016-01-02 19:00:00\n",
      "99990          929  2016-01-02 19:00:00\n",
      "99991          929  2016-01-02 19:00:00\n",
      "99992          929  2016-01-02 19:00:00\n",
      "99993          930  2016-01-02 19:00:00\n",
      "99994          931  2016-01-02 19:00:00\n",
      "99995          931  2016-01-02 19:00:00\n",
      "99996          931  2016-01-02 19:00:00\n",
      "99997          932  2016-01-02 19:00:00\n",
      "99998          932  2016-01-02 19:00:00\n",
      "99999          932  2016-01-02 19:00:00\n",
      "\n",
      "[41839 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "class RmHolidays(TransformerMixin):\n",
    "    def transform(self, df, **transform_params):\n",
    "        #df['holiday'] = df.apply(lambda x: all_holidays.get(x))\n",
    "        #df['holiday'] = df.apply(lambda x: holidayName(x.timestamp, x.site_id))\n",
    "        #print(temp_df['holiday'].notnull())\n",
    "        df = df.merge(holiday_df, on=['building_id','meter','timestamp','site_id'], how='left')\n",
    "        df = df.drop(df[df['holiday'].notnull()].index)\n",
    "        df = df.drop(['holiday'], axis=1)\n",
    "        return df\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "# Test \n",
    "rmHolidays = RmHolidays()\n",
    "print(rmHolidays.transform(train.head(100000).merge(building, on='building_id', how='left'))[['building_id','timestamp']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogSquareFeet(TransformerMixin):\n",
    "        \n",
    "    def transform(self, df, **transform_params):\n",
    "        df['log_square_feet'] = np.float16(np.log(df['square_feet']))\n",
    "        return df\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SetCatTypes(TransformerMixin):\n",
    "        \n",
    "    def transform(self, df, **transform_params):\n",
    "        df['primary_use']= df['primary_use'].astype('category')\n",
    "        df['meter'] = df[\"meter\"].astype('category')\n",
    "        df['site_id'] = df[\"site_id\"].astype('category')\n",
    "        df['building_id'] = df['building_id'].astype('category')\n",
    "        return df\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImputeCloudCoverage(TransformerMixin):\n",
    "        \n",
    "    def transform(self, df, **transform_params):\n",
    "        # set age of building to mediam of site_id\n",
    "        # else if set ot overall median\n",
    "        median = df['cloud_coverage'].median()\n",
    "        # Set all year_built NaNs to site mean for year_built\n",
    "        for i, i_median in df.groupby(['site_id'])['cloud_coverage'].median().items():\n",
    "            if not np.isnan(i_median):\n",
    "                df.loc[(df['cloud_coverage'].isnull()) & (df['site_id'] == i), 'cloud_coverage'] = i_median\n",
    "            else:\n",
    "                df.loc[(df['cloud_coverage'].isnull()) & (df['site_id'] == i), 'cloud_coverage'] = median\n",
    "        df['cloud_coverage'] = np.uint8(df['cloud_coverage'])\n",
    "        df['cloud_coverage'] = df['cloud_coverage']\n",
    "        return df\n",
    "        \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CloudTimeCat(TransformerMixin):\n",
    "        \n",
    "    def transform(self, df, **transform_params):\n",
    "        tempDf = df[['cloud_coverage', 'hour']].astype('int')\n",
    "        tempDf['cloud_coverage'] = (tempDf['cloud_coverage']).astype('int')\n",
    "        tempDf['hour'] = (tempDf['hour']).astype('int')\n",
    "        tempDf = tempDf.astype('str')\n",
    "        df['cloud_time_cat'] = 'c' + tempDf['cloud_coverage'] + 't' + tempDf['hour']\n",
    "        df['cloud_time_cat'] = df['cloud_time_cat'].astype('category')\n",
    "        return df\n",
    "        \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropCols(TransformerMixin):\n",
    "\n",
    "    def __init__(self, drop_cols):\n",
    "        self._drop_cols = drop_cols\n",
    "        \n",
    "    def transform(self, df, **transform_params):\n",
    "        return df.drop(self._drop_cols, axis=1)\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImputeYearBuilt(TransformerMixin):\n",
    "\n",
    "    def transform(self, df, **transform_params):\n",
    "        year_built_median = df['year_built'].median()\n",
    "        # Set all year_built NaNs to site mean for year_built\n",
    "        for i, i_median in df.groupby(['site_id'])['year_built'].median().items():\n",
    "            if not np.isnan(i_median):\n",
    "                df.loc[(df['year_built'].isnull()) & (df['site_id'] == i), 'year_built'] = i_median\n",
    "            else:\n",
    "                df.loc[(df['year_built'].isnull()) & (df['site_id'] == i), 'year_built'] = year_built_median\n",
    "        df['building_age'] = np.uint8(df['year_built']-1900)\n",
    "        return df\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddMeterDummies(TransformerMixin):\n",
    "        \n",
    "    def transform(self, df_a, **transform_params):\n",
    "        df = df_a\n",
    "        for i in range(4):\n",
    "            df['_meter_'+str(i)] = (df['building_id'].isin(\n",
    "                train.loc[train['meter'] == i].building_id.unique()))\n",
    "        return df\n",
    "        \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddTimeFeatures(TransformerMixin):\n",
    "        \n",
    "    def transform(self, df_a, **transform_params):\n",
    "        df = df_a\n",
    "        df['dayofweek'] = df['timestamp'].dt.dayofweek.astype('category') # vs weekend?\n",
    "        #df['weekday'] = df['timestamp'].dt.weekday.astype('category')\n",
    "        #df['dayofweek_hour'] = (df['timestamp'].dt.dayofweek * 24) + df['timestamp'].dt.hour\n",
    "        #df['dayofweek_hour'] = df['dayofweek_hour'].astype('category')\n",
    "        #df['week'] = df['timestamp'].dt.week.astype('category')\n",
    "        df['hour'] = df['timestamp'].dt.hour.astype('category')\n",
    "        return df\n",
    "        \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddRelativeHumidity(TransformerMixin):\n",
    "        \n",
    "    def transform(self, df_a, **transform_params):\n",
    "        df = df_a\n",
    "        # code here\n",
    "        return df\n",
    "        \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FillMean(TransformerMixin):\n",
    "\n",
    "    def __init__(self, cols):\n",
    "        self._cols = cols\n",
    "        \n",
    "    def transform(self, df, **transform_params):\n",
    "        for col in self._cols:\n",
    "            df[col] = df[col].fillna(df[col].mean())\n",
    "        return df\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FillZeros(TransformerMixin):\n",
    "\n",
    "    def __init__(self, cols):\n",
    "        self._cols = cols\n",
    "        \n",
    "    def transform(self, df, **transform_params):\n",
    "        for col in self._cols:\n",
    "            df[col] = df[col].fillna(0)\n",
    "        return df\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FillMedian(TransformerMixin):\n",
    "\n",
    "    def __init__(self, cols):\n",
    "        self._cols = cols\n",
    "        \n",
    "    def transform(self, df, **transform_params):\n",
    "        for col in self._cols:\n",
    "            df[col] = df[col].fillna(df[col].median())\n",
    "        return df\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class FillPopular(TransformerMixin):\n",
    "\n",
    "    def __init__(self, cols):\n",
    "        self._cols = cols\n",
    "        \n",
    "    def transform(self, df, **transform_params):\n",
    "        for col in self._cols:\n",
    "            df[col] = df[col].fillna(df[col].value_counts()[0])\n",
    "        return df\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarkNaNs(TransformerMixin):\n",
    "        \n",
    "    def transform(self, df, **transform_params):\n",
    "        for col in  df.columns[df.isna().any()].tolist():\n",
    "            df['_' + col + '_nan' ] = df[col].isnull()\n",
    "        return df\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GC(TransformerMixin):\n",
    "        \n",
    "    def transform(self, df, **transform_params):\n",
    "        gc.collect()\n",
    "        return df\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer, mean_squared_log_error, mean_squared_error\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "\n",
    "def rmsle(y, y_pred):\n",
    "    # hack to prevent negative numbers\n",
    "    return np.sqrt(mean_squared_log_error(y, y_pred.clip(0)))\n",
    "\n",
    "def rmse(y, y_pred):\n",
    "    # hack to prevent negative numbers\n",
    "    return mean_squared_error(y, y_pred.clip(0))\n",
    "\n",
    "def rmsee(y, y_pred):\n",
    "    # hack to prevent negative numbers\n",
    "    return np.sqrt(mean_squared_log_error(np.expm1(y.clip(0)), np.expm1(y_pred.clip(0))))\n",
    "    \n",
    "rmsle_scorer = make_scorer(\n",
    "    lambda y_true, y_pred : rmsle(y_true, y_pred), \n",
    "    greater_is_better=False)\n",
    "\n",
    "rmse_scorer = make_scorer(\n",
    "    lambda y_true, y_pred : rmsle(y_true, y_pred), \n",
    "    greater_is_better=False)\n",
    "\n",
    "rmsee_scorer = make_scorer(\n",
    "    lambda y_true, y_pred : rmsee(y_true, y_pred), \n",
    "    greater_is_better=False)\n",
    "\n",
    "def lbm_rmsle(y_true, y_pred):\n",
    "    return 'RMSLE', np.sqrt(np.mean(np.power(np.log1p(y_pred) - np.log1p(y_true), 2))), False\n",
    "\n",
    "# rob's custome function to do RMSLE while in the log1p space\n",
    "def lbm_rmslee(y_true, y_pred):\n",
    "    return 'RMSLEE', np.sqrt(np.mean(np.power(y_pred - y_true, 2))), False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_pipes = Pipeline(\n",
    "    steps=[\n",
    "        ('imputeWeather', ImputeWeather()),\n",
    "        ('fillMean',FillMean(['air_temperature','dew_temperature'\n",
    "                              , 'precip_depth_1_hr', 'sea_level_pressure'])),\n",
    "        ('imputeCloudCoverage', ImputeCloudCoverage()),\n",
    "        ('addWeatherLags3', AddWeatherLags(3)),\n",
    "        ('addWeatherLags72', AddWeatherLags(72)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "building_pipes = Pipeline(\n",
    "    steps=[\n",
    "        ('logSquareFeet', LogSquareFeet()),\n",
    "        ('imputeYearBuilt', ImputeYearBuilt()),\n",
    "        ('fillMean',FillMean(['floor_count'])),\n",
    "        ('dropClos', DropCols(['square_feet', 'year_built'])),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# pre_a_pipes is for preprocessing that doesn't change impute\n",
    "# values\n",
    "x_pipes = Pipeline(\n",
    "    steps=[\n",
    "        #('markNans',MarkNaNs()),\n",
    "        ('convertToDatetime', ConvertToDatetime()),\n",
    "        #('addHolidays', AddHolidays()),\n",
    "        #('rmHolidays', RmHolidays()),\n",
    "        ('addRelativeHumidity',AddRelativeHumidity()),\n",
    "        ('addTimeFeatures', AddTimeFeatures()),\n",
    "        ('setCatTypes', SetCatTypes()),\n",
    "        ('fillMean',FillMean([])),\n",
    "        ('fillZeros',FillZeros([])),\n",
    "        ('dropClos', DropCols(['timestamp'])),\n",
    "        ('GC', GC())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         building_id meter site_id                    primary_use  \\\n",
      "3573457          173     0       2                      Education   \n",
      "8315486          222     1       2  Entertainment/public assembly   \n",
      "40305643        1354     2      15                      Education   \n",
      "16083617         712     0       5                      Education   \n",
      "37204119        1344     2      15                      Education   \n",
      "32144852        1119     1      13                         Office   \n",
      "5105044          249     0       2  Entertainment/public assembly   \n",
      "36982844        1303     1      14                     Healthcare   \n",
      "20487823         945     2       9                         Office   \n",
      "8404196          217     1       2                      Education   \n",
      "6889602          241     0       2  Entertainment/public assembly   \n",
      "16963616         784     0       6                      Education   \n",
      "39666699        1381     2      15                         Office   \n",
      "26802058        1179     1      13  Entertainment/public assembly   \n",
      "30785716        1198     0      13                      Education   \n",
      "8763147          553     0       3                      Education   \n",
      "19415014         819     0       8                Public services   \n",
      "35698052        1296     2      14                         Office   \n",
      "26291343        1062     0      12                      Education   \n",
      "25410971        1023     0      10                      Education   \n",
      "\n",
      "          floor_count  log_square_feet  building_age  Unnamed: 0  \\\n",
      "3573457      3.740234              inf            74         NaN   \n",
      "8315486      3.740234         9.390625            39         NaN   \n",
      "40305643     3.740234        10.054688            64         NaN   \n",
      "16083617     1.000000        10.039062            76         NaN   \n",
      "37204119     3.740234              inf            74         NaN   \n",
      "32144852     3.740234              inf            70         NaN   \n",
      "5105044      3.740234              inf            76         NaN   \n",
      "36982844     3.740234              inf            70         NaN   \n",
      "20487823     3.740234              inf            70         NaN   \n",
      "8404196      3.740234              inf           103         NaN   \n",
      "6889602      3.740234        10.859375            74         NaN   \n",
      "16963616     3.740234              inf            70         NaN   \n",
      "39666699     3.740234              inf            63         NaN   \n",
      "26802058     3.740234              inf            70         NaN   \n",
      "30785716     3.740234              inf            70         NaN   \n",
      "8763147      3.740234        10.539062            62         NaN   \n",
      "19415014     1.000000         8.757812            70         NaN   \n",
      "35698052     3.740234         9.085938            70         NaN   \n",
      "26291343     3.740234              inf            70         NaN   \n",
      "25410971     2.000000              inf            70         NaN   \n",
      "\n",
      "          air_temperature  cloud_coverage  ...  wind_direction_mean_lag72  \\\n",
      "3573457               NaN             NaN  ...                        NaN   \n",
      "8315486               NaN             NaN  ...                        NaN   \n",
      "40305643              NaN             NaN  ...                        NaN   \n",
      "16083617              NaN             NaN  ...                        NaN   \n",
      "37204119              NaN             NaN  ...                        NaN   \n",
      "32144852              NaN             NaN  ...                        NaN   \n",
      "5105044               NaN             NaN  ...                        NaN   \n",
      "36982844              NaN             NaN  ...                        NaN   \n",
      "20487823              NaN             NaN  ...                        NaN   \n",
      "8404196               NaN             NaN  ...                        NaN   \n",
      "6889602               NaN             NaN  ...                        NaN   \n",
      "16963616              NaN             NaN  ...                        NaN   \n",
      "39666699              NaN             NaN  ...                        NaN   \n",
      "26802058              NaN             NaN  ...                        NaN   \n",
      "30785716              NaN             NaN  ...                        NaN   \n",
      "8763147               NaN             NaN  ...                        NaN   \n",
      "19415014              NaN             NaN  ...                        NaN   \n",
      "35698052              NaN             NaN  ...                        NaN   \n",
      "26291343              NaN             NaN  ...                        NaN   \n",
      "25410971              NaN             NaN  ...                        NaN   \n",
      "\n",
      "          wind_direction_max_lag72  wind_direction_min_lag72  \\\n",
      "3573457                        NaN                       NaN   \n",
      "8315486                        NaN                       NaN   \n",
      "40305643                       NaN                       NaN   \n",
      "16083617                       NaN                       NaN   \n",
      "37204119                       NaN                       NaN   \n",
      "32144852                       NaN                       NaN   \n",
      "5105044                        NaN                       NaN   \n",
      "36982844                       NaN                       NaN   \n",
      "20487823                       NaN                       NaN   \n",
      "8404196                        NaN                       NaN   \n",
      "6889602                        NaN                       NaN   \n",
      "16963616                       NaN                       NaN   \n",
      "39666699                       NaN                       NaN   \n",
      "26802058                       NaN                       NaN   \n",
      "30785716                       NaN                       NaN   \n",
      "8763147                        NaN                       NaN   \n",
      "19415014                       NaN                       NaN   \n",
      "35698052                       NaN                       NaN   \n",
      "26291343                       NaN                       NaN   \n",
      "25410971                       NaN                       NaN   \n",
      "\n",
      "          wind_direction_std_lag72  wind_speed_mean_lag72  \\\n",
      "3573457                        NaN                    NaN   \n",
      "8315486                        NaN                    NaN   \n",
      "40305643                       NaN                    NaN   \n",
      "16083617                       NaN                    NaN   \n",
      "37204119                       NaN                    NaN   \n",
      "32144852                       NaN                    NaN   \n",
      "5105044                        NaN                    NaN   \n",
      "36982844                       NaN                    NaN   \n",
      "20487823                       NaN                    NaN   \n",
      "8404196                        NaN                    NaN   \n",
      "6889602                        NaN                    NaN   \n",
      "16963616                       NaN                    NaN   \n",
      "39666699                       NaN                    NaN   \n",
      "26802058                       NaN                    NaN   \n",
      "30785716                       NaN                    NaN   \n",
      "8763147                        NaN                    NaN   \n",
      "19415014                       NaN                    NaN   \n",
      "35698052                       NaN                    NaN   \n",
      "26291343                       NaN                    NaN   \n",
      "25410971                       NaN                    NaN   \n",
      "\n",
      "          wind_speed_max_lag72  wind_speed_min_lag72  wind_speed_std_lag72  \\\n",
      "3573457                    NaN                   NaN                   NaN   \n",
      "8315486                    NaN                   NaN                   NaN   \n",
      "40305643                   NaN                   NaN                   NaN   \n",
      "16083617                   NaN                   NaN                   NaN   \n",
      "37204119                   NaN                   NaN                   NaN   \n",
      "32144852                   NaN                   NaN                   NaN   \n",
      "5105044                    NaN                   NaN                   NaN   \n",
      "36982844                   NaN                   NaN                   NaN   \n",
      "20487823                   NaN                   NaN                   NaN   \n",
      "8404196                    NaN                   NaN                   NaN   \n",
      "6889602                    NaN                   NaN                   NaN   \n",
      "16963616                   NaN                   NaN                   NaN   \n",
      "39666699                   NaN                   NaN                   NaN   \n",
      "26802058                   NaN                   NaN                   NaN   \n",
      "30785716                   NaN                   NaN                   NaN   \n",
      "8763147                    NaN                   NaN                   NaN   \n",
      "19415014                   NaN                   NaN                   NaN   \n",
      "35698052                   NaN                   NaN                   NaN   \n",
      "26291343                   NaN                   NaN                   NaN   \n",
      "25410971                   NaN                   NaN                   NaN   \n",
      "\n",
      "          dayofweek  hour  \n",
      "3573457           3     8  \n",
      "8315486           1     0  \n",
      "40305643          3    12  \n",
      "16083617          3    23  \n",
      "37204119          0     0  \n",
      "32144852          6    19  \n",
      "5105044           0     3  \n",
      "36982844          4    19  \n",
      "20487823          6     8  \n",
      "8404196           6    19  \n",
      "6889602           5    10  \n",
      "16963616          1    15  \n",
      "39666699          0    12  \n",
      "26802058          0     7  \n",
      "30785716          5    12  \n",
      "8763147           3     8  \n",
      "19415014          0     5  \n",
      "35698052          0    20  \n",
      "26291343          3    10  \n",
      "25410971          2    18  \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20 rows x 73 columns]\n",
      "(41697600, 73)\n"
     ]
    }
   ],
   "source": [
    "test_X = x_pipes.transform(\n",
    "    test\n",
    "        .merge(building_pipes.transform(building), on='building_id', how='left').drop(['row_id'], axis=1)\n",
    "        .merge(weather_pipes.transform(weather_test), on=['site_id', 'timestamp'], how='left')\n",
    "    )\n",
    "\n",
    "print(test_X.sample(n=20,  random_state=42))\n",
    "print(test_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Empty DataFrame\n",
      "Columns: [building_id, meter, site_id, primary_use, floor_count, log_square_feet, building_age, Unnamed: 0, air_temperature, cloud_coverage, dew_temperature, precip_depth_1_hr, sea_level_pressure, wind_direction, wind_speed, air_temperature_mean_lag3, air_temperature_max_lag3, air_temperature_min_lag3, air_temperature_std_lag3, cloud_coverage_mean_lag3, cloud_coverage_max_lag3, cloud_coverage_min_lag3, cloud_coverage_std_lag3, dew_temperature_mean_lag3, dew_temperature_max_lag3, dew_temperature_min_lag3, dew_temperature_std_lag3, precip_depth_1_hr_mean_lag3, precip_depth_1_hr_max_lag3, precip_depth_1_hr_min_lag3, precip_depth_1_hr_std_lag3, sea_level_pressure_mean_lag3, sea_level_pressure_max_lag3, sea_level_pressure_min_lag3, sea_level_pressure_std_lag3, wind_direction_mean_lag3, wind_direction_max_lag3, wind_direction_min_lag3, wind_direction_std_lag3, wind_speed_mean_lag3, wind_speed_max_lag3, wind_speed_min_lag3, wind_speed_std_lag3, air_temperature_mean_lag72, air_temperature_max_lag72, air_temperature_min_lag72, air_temperature_std_lag72, cloud_coverage_mean_lag72, cloud_coverage_max_lag72, cloud_coverage_min_lag72, cloud_coverage_std_lag72, dew_temperature_mean_lag72, dew_temperature_max_lag72, dew_temperature_min_lag72, dew_temperature_std_lag72, precip_depth_1_hr_mean_lag72, precip_depth_1_hr_max_lag72, precip_depth_1_hr_min_lag72, precip_depth_1_hr_std_lag72, sea_level_pressure_mean_lag72, sea_level_pressure_max_lag72, sea_level_pressure_min_lag72, sea_level_pressure_std_lag72, wind_direction_mean_lag72, wind_direction_max_lag72, wind_direction_min_lag72, wind_direction_std_lag72, wind_speed_mean_lag72, wind_speed_max_lag72, wind_speed_min_lag72, wind_speed_std_lag72, dayofweek, hour]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 73 columns], Series([], Name: meter_reading, dtype: float32))\n"
     ]
    }
   ],
   "source": [
    "def getOutsideFoldXY(train_index):\n",
    "    X = train.iloc[train_index].drop('meter_reading', axis=1)\n",
    "    X_buildings = building[building['building_id'].isin(X['building_id'].unique())]\n",
    "    X_weather = building[building['building_id'].isin(X['building_id'].unique())]\n",
    "    X = x_pipes.transform(\n",
    "        X\n",
    "            .merge(building_pipes.transform(X_buildings), on='building_id', how='left')\n",
    "            .merge(weather_train_trans, on=['site_id', 'timestamp'], how='left')\n",
    "        )\n",
    "    f_train_y = np.log1p(train.iloc[train_index]['meter_reading'])\n",
    "    print(X.columns)\n",
    "    return X,f_train_y\n",
    "\n",
    "\n",
    "\n",
    "def getInFoldXY(train_index):\n",
    "    X = train.iloc[train_index]\n",
    "    X_buildings = building[building['building_id'].isin(X['building_id'].unique())]\n",
    "    X = X.merge(building_pipes.transform(X_buildings), on='building_id', how='left')\n",
    "    X_weather = weather_train[\n",
    "        (weather_train['site_id'].isin(X['site_id'].unique())) \n",
    "         & (weather_train['timestamp'].isin(X['timestamp'].unique())) \n",
    "    ]\n",
    "    X = x_pipes.transform(\n",
    "        rmHolidays.transform(\n",
    "            X.merge(weather_pipes.transform(X_weather), how='left')))\n",
    "    return X.drop('meter_reading', axis=1),  np.log1p(X['meter_reading'])\n",
    "\n",
    "\n",
    "print(getInFoldXY(train.head(10).index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_params = {\n",
    "    'n_estimators' : 500, # for accuracy use large numbers like 6000 \n",
    "    'learning_rate': 0.4,\n",
    "    'feature_fraction' : 0.9,\n",
    "    'subsample' : 0.1,  # \n",
    "    'subsample_freq' : 1,\n",
    "    'num_leaves' : 20,\n",
    "    'max_depth' : 10,\n",
    "    'metric':'rmse',\n",
    "    'lambda_l1' : 1,  \n",
    "    'lambda_l2': 1,\n",
    "    'verbose': 100\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "folds = 5\n",
    "\n",
    "# this stratified strategy from\n",
    "# https://www.kaggle.com/isaienkov/lightgbm-fe-1-19/notebook\n",
    "kf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "\n",
    "models = []\n",
    "best_scores = []\n",
    "for train_index, val_index in kf.split(train, train['building_id']):\n",
    "    f_train_X, f_train_y = getInFoldXY(train_index)\n",
    "    f_val_X, f_val_y = getInFoldXY(val_index)\n",
    "    gbm = LGBMRegressor(**gbm_params)\n",
    "    gbm.fit(f_train_X, f_train_y,\n",
    "        eval_set=[(f_val_X, f_val_y)],\n",
    "        # https://www.kaggle.com/c/ashrae-energy-prediction/discussion/114722#latest-660848\n",
    "        # eval_metric=lbm_rmslee,\n",
    "        early_stopping_rounds=20)\n",
    "    models.append(gbm)\n",
    "    #y_pred = gbm.predict(f_val_X, num_iteration=gbm.best_iteration_)\n",
    "    # eval\n",
    "    #rmsle_score = lbm_rmslee(f_val_X, y_pred)[1]\n",
    "    best_scores.append(gbm.best_score_)\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for score in best_scores:\n",
    "    print(score['valid_0']['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "imprtc_df = pd.DataFrame()\n",
    "imprtc_df['feature'] = test_X.columns   \n",
    "imprtc_df['importance'] = models[0].feature_importances_\n",
    "imprtc_df.sort_values('importance', ascending=False, inplace= True)\n",
    "print(imprtc_df)\n",
    "print(test_X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "# Cross val models ensemble \n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i=0\n",
    "res=[]\n",
    "step_size = 50000\n",
    "for j in tqdm(range(int(np.ceil(test_X.shape[0]/50000)))):\n",
    "    res.append(np.expm1(sum([model.predict(test_X.iloc[i:i+step_size]) for model in models])/folds))\n",
    "    #res.append(np.expm1(gbm.predict(test_X.iloc[i:i+step_size])))\n",
    "    i+=step_size\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = np.concatenate(res)\n",
    "print(len(res))\n",
    "submission = pd.read_csv('../input/ashrae-energy-prediction/sample_submission.csv')\n",
    "submission['meter_reading'] = res\n",
    "submission.loc[submission['meter_reading']<0, 'meter_reading'] = 0\n",
    "submission.to_csv('submission.csv.zip', index=False)\n",
    "submission.sample(n=20,  random_state=42))\n",
    "submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "# Single model fit\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "gbm = LGBMRegressor(**gbm_params)\n",
    "f_train_X, f_train_y = getInFoldXY(train.index)\n",
    "gbm.fit(f_train_X, f_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "res=[]\n",
    "step_size = 50000\n",
    "for j in tqdm(range(int(np.ceil(test_X.shape[0]/50000)))):\n",
    "    res.append(np.expm1(sum([model.predict(test_X.iloc[i:i+step_size]) for model in models])/folds))\n",
    "    #res.append(np.expm1(gbm.predict(test_X.iloc[i:i+step_size])))\n",
    "    i+=step_size\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
